# -*- coding: utf-8 -*-
"""MLT_Submission_Proyek_Akhir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q4lMrK9bgPv0Y-CuZl9u5-IqucB2Ev1Y

# Proyek Akhir : Sistem Rekomendasi Destinasi Wisata di Indonesia

## **A. Project Overview**

### Latar Belakang

Industri pariwisata merupakan salah satu sektor penting yang mendukung pertumbuhan ekonomi, baik secara lokal maupun global. Seiring berkembangnya teknologi dan meningkatnya akses informasi, wisatawan kini dihadapkan pada banyaknya pilihan destinasi wisata yang tersedia secara daring. Hal ini menciptakan tantangan baru, yaitu kesulitan dalam menentukan destinasi yang paling sesuai dengan preferensi pribadi. Ketika pengguna tidak memiliki informasi atau referensi yang cukup, mereka cenderung memilih tempat yang sudah populer, sehingga mengurangi potensi destinasi lainnya yang tidak kalah menarik namun kurang terekspos `(Yulianto et al., 2023)`.

Untuk mengatasi permasalahan ini, pengembangan sistem rekomendasi destinasi wisata menjadi sangat penting. Sistem ini bertujuan untuk memberikan saran yang relevan dan personalisasi berdasarkan preferensi, riwayat, atau pola perilaku pengguna. Dengan demikian, pengguna tidak perlu menelusuri semua pilihan secara manual, melainkan dapat langsung mendapatkan rekomendasi destinasi yang sesuai dengan keinginan mereka.

Menurut riset yang dilakukan oleh `Goel & Rizvi (2024)`, implementasi sistem rekomendasi menggunakan algoritma hybrid (gabungan content-based filtering dan collaborative filtering) dapat meningkatkan relevansi saran destinasi dan mengurangi cold start problem yang sering terjadi pada sistem rekomendasi berbasis pengguna baru atau item baru.

Penelitian lain yang dilakukan oleh `Syakura (2024)` menunjukkan bahwa sistem rekomendasi destinasi wisata berbasis content-based dapat membantu wisatawan untuk menemukan tempat yang relevan meskipun mereka belum memberikan banyak rating sebelumnya. Sementara itu, sistem berbasis collaborative filtering yang dikembangkan di Semarang terbukti efektif dalam merekomendasikan tempat wisata baru yang belum populer tetapi sesuai dengan pola pengguna lain `(Cholil et al., 2023)`.

Melalui proyek ini, diharapkan sistem yang dibangun tidak hanya mempermudah wisatawan dalam merencanakan perjalanan, tetapi juga memberikan dampak positif bagi sektor pariwisata lokal dengan memperkenalkan lebih banyak destinasi kepada pengguna. Dengan memanfaatkan data dan teknologi, sistem rekomendasi menjadi solusi cerdas dan adaptif di era digital untuk meningkatkan pengalaman wisata yang lebih personal dan efisien.

<br>

📚 Referensi:
- Cholil, S. R., Rizki, N. A., & Hanifah, T. F. (2023). Sistem rekomendasi tempat wisata di Kota Semarang menggunakan metode collaborative filtering. JIKO (Jurnal Informatika dan Komputer), 7(1). [LINK](http://dx.doi.org/10.26798/jiko.v7i1.727)
- Goel, S., & Rizvi, S. W. A. (2024). Travel recommendation system using content and collaborative filtering. Journal of Mechanical and Construction Engineering (JMCE), 4(2), 1–8. [LINK](https://doi.org/10.54060/a2zjournals.jmce.63)
- Syakura, Z. I. (2024). Sistem rekomendasi destinasi wisata di Kota Surabaya menggunakan metode content based filtering dan neural collaborative filtering. Institut Teknologi Sepuluh Nopember Repository. [LINK](http://repository.its.ac.id/id/eprint/114885)
- Yulianto, A., Hadi, W., & Yulianto, Y. (2023). Analisis preferensi wisatawan terhadap pilihan berwisata di Sendang Sombomerti Depok Sleman Yogyakarta. Journal of Tourism and Economic, 6(2), 143-152. [LINK](https://doi.org/10.36594/jtec/tq2fkg11)

## **B. Business Understanding**

### **Problem Statements**

Berdasarkan latar belakang di atas, berikut ini merupakan rincian masalah yang dapat diselesaikan pada proyek ini:
- **Bagaimana cara memberikan rekomendasi destinasi wisata yang relevan berdasarkan deskripsi dan kategori konten?**

    Masalah ini berfokus pada pemanfaatan informasi terkait karakteristik destinasi, seperti kategori (budaya, alam, dll.) dan deskripsi tempat untuk memberikan rekomendasi yang lebih personal dan relevan bagi pengguna. Dengan pendekatan content-based filtering, sistem harus dapat menganalisis dan menyarankan destinasi yang sesuai dengan preferensi pengguna, berdasarkan kesamaan fitur-fitur tersebut.

- **Bagaimana cara menggunakan data rating pengguna untuk meningkatkan akurasi rekomendasi?**

    Data yang berisi interaksi pengguna terhadap destinasi wisata, seperti rating yang diberikan oleh pengguna, sangat penting untuk meningkatkan kualitas rekomendasi. Dengan menggabungkan teknik content-based dan collaborative filtering, sistem dapat mengatasi kekurangan data pada pengguna baru dan memperbaiki akurasi saran yang diberikan. Sistem ini dapat menyesuaikan rekomendasi dengan pola rating yang diberikan oleh pengguna lain dengan preferensi serupa, meningkatkan relevansi rekomendasi yang disarankan.

- **Bagaimana cara mengukur relevansi rekomendasi agar sistem dapat memberikan hasil yang tepat?**

    Sistem rekomendasi harus mampu memberikan hasil yang sesuai dengan kebutuhan pengguna. Oleh karena itu, diperlukan metrik evaluasi yang efektif untuk memantau dan mengukur sejauh mana sistem mampu menghasilkan rekomendasi yang relevan dan tepat sasaran.

### **Goals/Tujuan**

Tujuan utama dari proyek ini adalah untuk membangun sistem rekomendasi destinasi wisata yang relevan dan adaptif dengan memanfaatkan informasi konten destinasi serta interaksi pengguna sebelumnya. Sistem ini diharapkan dapat membantu wisatawan dalam menemukan destinasi yang sesuai dengan preferensi mereka secara lebih efisien, mengurangi ketergantungan pada pencarian manual, serta memperluas eksposur terhadap destinasi yang kurang populer namun potensial.

Secara lebih spesifik, tujuan proyek ini meliputi:
- **Membangun sistem rekomendasi berbasis konten yang efisien dengan memanfaatkan deskripsi dan kategori destinasi wisata.**

    Sistem ini akan memanfaatkan informasi deskriptif dan klasifikasi destinasi untuk mencocokkan rekomendasi dengan minat pengguna yang sudah pernah mengunjungi tempat wisata tertentu.

- **Mengembangkan sistem rekomendasi destinasi wisata berbasis kolaboratif yang mempertimbangkan pola penilaian pengguna.**

    Dengan menganalisis data rating yang diberikan pengguna terhadap destinasi tertentu, sistem diharapkan dapat menyarankan tempat wisata yang relevan berdasarkan kesamaan pola preferensi antar pengguna.

- **Melakukan evaluasi terhadap performa sistem rekomendasi menggunakan metrik yang sesuai.**

    Evaluasi dilakukan untuk menilai tingkat relevansi dan akurasi rekomendasi yang dihasilkan, guna memastikan bahwa sistem memberikan saran yang tepat sasaran dan bermanfaat bagi pengguna.

### **Solution Statement**

Untuk mencapai tujuan proyek, dilakukan serangkaian pendekatan sebagai berikut:

- **Content-based Filtering**

    Pendekatan ini memanfaatkan informasi tekstual pada deskripsi dan kategori destinasi wisata untuk merekomendasikan tempat yang memiliki karakteristik serupa dengan destinasi yang disukai pengguna sebelumnya. Langkah-langkah yang dilakukan adalah sebagai berikut:

    - Preprocessing

      Deskripsi dan kategori destinasi digabungkan dan dibersihkan, lalu diubah menjadi representasi numerik menggunakan metode TF-IDF Vectorizer.

    - Pembangunan Model

      Kesamaan antar destinasi dihitung menggunakan cosine similarity berdasarkan vektor TF-IDF, sehingga sistem dapat merekomendasikan destinasi yang memiliki konten serupa.

    - Evaluasi

      Kinerja sistem diukur menggunakan metrik Precision@10, yang mengevaluasi proporsi destinasi yang relevan dari 10 rekomendasi teratas.

- **Collaborative Filtering**
    
    Pendekatan ini mengandalkan data interaksi pengguna berupa rating untuk menyarankan destinasi yang disukai oleh pengguna lain dengan preferensi serupa. Berikut adalah langkah-langkah yang dilakukan:

    - Encoding Data
      
      ID pengguna dan destinasi dikonversi menjadi indeks numerik untuk mempermudah proses pelatihan dalam model neural network.

    - Normalisasi Rating

      Rating dinormalisasi ke rentang [0,1] guna memastikan stabilitas pembelajaran model.

    - Pembangunan Model

      Model dikembangkan menggunakan embedding layer untuk memetakan pengguna dan destinasi ke dalam representasi vektor, dan menghasilkan prediksi rating untuk pasangan pengguna–destinasi.
    
    - Evaluasi

      Metrik yang digunakan meliputi Root Mean Square Error (RMSE) dan Mean Absolute Error (MAE), yang menilai akurasi prediksi model terhadap rating aktual.

---

## **1. Import Library yang Dibutuhkan**
"""

!pip install Sastrawi

# ==========================
# 🔗 Google Drive Integration
# ==========================
from google.colab import drive
import os  # Navigasi direktori & path

# ==========================
# ⚙️ Konfigurasi Umum & Seed
# ==========================
import pandas as pd
import numpy as np
import random
import warnings

# Konfigurasi warning & seed
pd.options.mode.chained_assignment = None
warnings.simplefilter(action='ignore', category=FutureWarning)

seed = 0
np.random.seed(seed)
random.seed(seed)

# ==========================
# 📊 Visualisasi Data
# ==========================
import matplotlib.pyplot as plt
import seaborn as sns

# ==========================
# 🧹 Teks & NLP Preprocessing
# ==========================
from sklearn.feature_extraction.text import TfidfVectorizer
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from sklearn.metrics.pairwise import cosine_similarity

# ==========================
# 📏 Evaluasi Model
# ==========================
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ==========================
# 🧠 Deep Learning
# ==========================
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# ==========================
# 📦 Library Tambahan
# ==========================
import kagglehub

from IPython.display import display, HTML

import shutil

# Mount Google Drive
drive.mount('/content/drive')

# Path tujuan proyek di Google Drive
target_path = '/content/drive/MyDrive/MLT/Proyek_Akhir'

# Cek apakah path ada, lalu berpindah ke direktori tersebut
if os.path.exists(target_path):
    os.chdir(target_path)
    print(f"✅ Berhasil berpindah ke direktori: {os.getcwd()}")
else:
    print(f"❌ Path tidak ditemukan: {target_path}. Periksa kembali lokasi foldernya.")

"""---

## **2. Data Understanding**

Data Understanding merupakan proses memahami informasi dalam data dan menentukan kualitas dari data tersebut.

### **2.1. Informasi Dataset**

Dataset `Indonesia Tourism Destination` yang digunakan pada proyek ini diambil pada laman [Kaggle](https://www.kaggle.com/datasets/aprabowo/indonesia-tourism-destination/data). Dataset ini ditujukan untuk membangun sistem rekomendasi tempat wisata berdasarkan preferensi pengguna serta parameter seperti kota, harga, kategori, dan waktu. Dataset ini berisi data tempat wisata di `5 kota besar di Indonesia, yaitu Jakarta, Yogyakarta, Semarang, Bandung, dan Surabaya`.

| Jenis      | Keterangan                                                                            |
| ---------- | ------------------------------------------------------------------------------------- |
| Title      | Indonesia Tourism Destination                                                         |
| Source     | [Kaggle](https://www.kaggle.com/datasets/aprabowo/indonesia-tourism-destination/data) |
| Maintainer | [A_Prabowo](https://www.kaggle.com/datasets/aprabowo)                                 |
| License    | Data files © Original Authors                                                         |
| Visibility | Publik                                                                                |
| Tags       | Beginner, Travel, Asia, Recommender Systems                                           |
| Usability  | 8.24                                                                                  |

### **2.2. Mengambil Data Dari Kaggle**
"""

# Path tujuan akhir di Google Drive
final_dir = "/content/drive/MyDrive/MLT/Proyek_Akhir/dataset"
os.makedirs(final_dir, exist_ok=True)

def download_kaggle_dataset_to_drive(dataset_id: str, target_dir: str):
    try:
        # Unduh dataset ke path default kagglehub
        source_path = kagglehub.dataset_download(dataset_id)
        print(f"✅ Dataset berhasil diunduh: {dataset_id}")
        print(f"📂 Lokasi awal: {source_path}")
        print("🔄 Memindahkan ke folder Google Drive...")

        # Pindahkan isi folder ke target_dir
        for filename in os.listdir(source_path):
            src = os.path.join(source_path, filename)
            dst = os.path.join(target_dir, filename)
            shutil.copy2(src, dst)

        print(f"✅ Dataset berhasil dipindahkan ke: {target_dir}")
        print("📌 Isi folder:", os.listdir(target_dir))

    except Exception as e:
        print(f"❌ Gagal download atau pindah dataset: {dataset_id}")
        print(f"📌 Error: {e}")

# Eksekusi
download_kaggle_dataset_to_drive("aprabowo/indonesia-tourism-destination", final_dir)

"""### **2.3. Memuat Data**

Dataset diimpor ke dalam lingkungan kerja menggunakan pustaka Pandas dan disusun dalam format dataframe. Proses ini bertujuan untuk memastikan data dapat diakses dan diolah dengan lebih mudah dalam proses analisis selanjutnya.
"""

# Path folder dataset
url = "/content/drive/MyDrive/MLT/Proyek_Akhir/dataset"

# Load keempat dataset ke dalam dataframe dengan nama yang informatif
df_tourism      = pd.read_csv(f"{url}/tourism_with_id.csv")          # Data wisata
df_ratings      = pd.read_csv(f"{url}/tourism_rating.csv")           # Rating antar user dan tempat

print('Jumlah data informasi tempat wisata:', len(df_tourism.Place_Id.unique()))
print('Jumlah data pengguna yang memberi rating:', len(df_ratings.User_Id.unique()))
print('Jumlah total rating yang tercatat :', len(df_ratings))

df_tourism.head(2)

df_ratings.head(2)

"""### **2.4. Karakteristik Dataset**

Dataset yang digunakan pada proyek ini, yaitu `tourism_with_id.csv` dan `tourism_rating.csv`.

1. `tourism_with_id.csv`
    Berisi informasi detail mengenai tempat wisata di lima kota besar Indonesia. Terdapat total 437 tempat wisata.

    Kolom-kolom pada file ini antara lain:
    - `Place_Id` : Identifikasi unik untuk setiap destinasi wisata.
    - `Place_Name` : Nama destinasi wisata.
    - `Description` : Deskripsi singkat tentang destinasi.
    - `Category` : Kategori destinasi (misalnya: Budaya, Alam).
    - `City` : Kota tempat destinasi berada.
    - `Price` : Harga tiket masuk.
    - `Rating` : Rating rata-rata dari pengguna (0-5).
    - `Time_Minutes` : Waktu yang dibutuhkan untuk mengunjungi (dalam menit).
    - `Coordinate`: Koordinat geografis.
    - `Lat`: Latitude lokasi.
    - `Long` : Longitude lokasi.
    - `Unnamed: 11` : Kolom kosong.
    - `Unnamed: 12` : Nilai duplikat dari Place_id.


2. `tourism_rating.csv`
    Digunakan sebagai data interaksi antara pengguna dan tempat wisata, yang akan digunakan dalam sistem rekomendasi berbasis rating. Terdapat 10.000 data rating pengguna terhadap destinasi wisata tertentu.

    Kolom-kolom pada file ini:
    - `User_Id` : ID unik untuk setiap pengguna yang memberi rating.
    - `Place_Id` : ID untuk setiap destinasi wisata yang diberi rating.
    - `Rating` : Rating yang diberikan oleh pengguna terhadap destinasi wisata (0-5).

**Insight:**
- **Relasi antar dataset**
    - `Place_Id` pada `tourism_rating.csv` berfungsi sebagai foreign key yang menghubungkan ke `Place_Id` pada `tourism_with_id.csv`. Ini memungkinkan integrasi data antara informasi destinasi wisata dengan data interaksi pengguna (rating), sehingga kita bisa menganalisis preferensi pengguna berdasarkan karakteristik destinasi.

- **`User_Id` pada `tourism_rating.csv` memungkinkan kita untuk:**
    - Melakukan analisis perilaku pengguna secara individual, misalnya memahami pola penilaian mereka terhadap berbagai kategori destinasi.
    - Membentuk segmentasi pengguna berdasarkan preferensi, yang bermanfaat untuk personalisasi rekomendasi, misalnya menyarankan destinasi wisata berdasarkan kecenderungan rating pengguna yang mirip.

### **2.5. Data Assessing**

Pemeriksaan data ini dilakukan dengan menjalankan proses assessing data yang bertujuan untuk mengidentifikasi masalah yang terdapat dalam data dan memastikan data tersebut berkualitas.

Setelah data berhasil dikumpulkan, dilakukan evaluasi kualitas data melalui beberapa pengecekan penting, yaitu:

- `Duplikasi Data`
    
    Dilakukan pemeriksaan apakah terdapat baris data yang tercatat lebih dari satu kali. Data duplikat dapat memperkenalkan bias dalam pelatihan model dan perlu dihapus.

- `Missing Values`

    Dicek apakah terdapat nilai kosong (missing) pada kolom-kolom penting. Kehadiran nilai kosong dapat menurunkan kualitas model dan, jika ditemukan, perlu ditangani melalui imputasi atau penghapusan.

- `Kolom Yang Tidak Relevan`

    Dilakukan pengecekan apakah terdapat kolom yang memuat informasi yang sama (kolom duplikat), karena keberadaan kolom seperti ini dapat menyebabkan redundansi dan perlu dihapus untuk efisiensi.

#### **2.5.1. Menilai Data**

##### **a. Data Tourism**
"""

# Menampilkan ringkasan informasi dari dataset
df_tourism.info()

"""Dari eksekusi method `df_loan.info()` terdapat:

- Terdapat 8 kolom numerik dengan tipe data `int64` dan `float64` yaitu: `Place_Id`, `Price`, `Rating`, `Time_Minutes`, `Lat`, `Long`, `Unnamed: 11`, `Unnamed: 12`.
- Terdapat 5 kolom dengan tipe data `object` yaitu: `Place_Name`, `Description`, `Category`, `City`, `Coordinate`.
"""

df_tourism.describe(include="all")

"""Fungsi `describe(include="all")` memberikan informasi statistik pada masing-masing kolom, antara lain:
- `Count` adalah jumlah nilai non-null (tidak kosong) pada kolom tersebut. Berlaku untuk semua jenis data.
- `Mean` adalah nilai rata-rata. Hanya muncul pada kolom bertipe numerik.
- `Std` adalah standar deviasi (seberapa tersebar data dari rata-rata). Hanya muncul untuk kolom numerik.
- `Min` yaitu nilai minimum dari setiap kolom numerik.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- `75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum pada kolom numerik.
- `Unique` adalah	jumlah nilai unik (berbeda) dalam kolom. Hanya muncul untuk kolom kategorikal/objek.
- `Top` adalah nilai yang paling sering muncul (modus) dalam kolom kategorikal.
- `Freq` adalah frekuensi kemunculan nilai top. Berapa kali nilai tersebut muncul.
"""

df_tourism.shape

"""Dari eksekusi method `df_tourism.shape` Terlihat:

| JUMLAH BARIS AWAL | JUMLAH KOLOM AWAL |
| ------ | ------ |
| 437 | 13 |

<br>

##### **b. Data Rating**
"""

# Menampilkan ringkasan informasi dari dataset
df_ratings.info()

"""Dari eksekusi method `df_loan.info()` terdapat:

- Terdapat 3 kolom numerik dengan tipe data `int64` dan `float64` yaitu: `User_Id`, `Place_Id`, dan `Place_Ratings`.
"""

df_ratings.describe(include="all")

"""Fungsi `describe(include="all")` memberikan informasi statistik pada masing-masing kolom, antara lain:
- `Count` adalah jumlah nilai non-null (tidak kosong) pada kolom tersebut. Berlaku untuk semua jenis data.
- `Mean` adalah nilai rata-rata. Hanya muncul pada kolom bertipe numerik.
- `Std` adalah standar deviasi (seberapa tersebar data dari rata-rata). Hanya muncul untuk kolom numerik.
- `Min` yaitu nilai minimum dari setiap kolom numerik.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- `75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum pada kolom numerik.
- `Unique` adalah	jumlah nilai unik (berbeda) dalam kolom. Hanya muncul untuk kolom kategorikal/objek.
- `Top` adalah nilai yang paling sering muncul (modus) dalam kolom kategorikal.
- `Freq` adalah frekuensi kemunculan nilai top. Berapa kali nilai tersebut muncul.
"""

df_ratings.shape

"""Dari eksekusi method `df_tourism.shape` Terlihat:

| JUMLAH BARIS AWAL | JUMLAH KOLOM AWAL |
| ------ | ------ |
| 10000 | 3 |

<br>

#### **2.5.2. Cek Duplikasi Data**

Pertama, dilakukan pemeriksaan untuk memastikan tidak ada duplikasi pada kolom `Place_Id`, karena setiap destinasi wisata seharusnya memiliki ID yang unik.
"""

# Cek duplikat berdasarkan Place_Id
duplicate_place_id = df_tourism[df_tourism.duplicated('Place_Id', keep=False)]

print("Mengecek Duplikat berdasarkan Place_Id:")
duplicate_place_id

"""Selain `Place_Id`, juga perlu diperiksa apakah ada tempat wisata yang tercatat lebih dari sekali berdasarkan nama tempat `(Place_Name)`, yang bisa mengindikasikan duplikasi konten meskipun ID berbeda."""

# Cek duplikat berdasarkan Place_Name
duplicate_place_name = df_tourism[df_tourism.duplicated('Place_Name', keep=False)]

print("Mengecek Duplikat berdasarkan Place_Name:")
duplicate_place_name

"""Pada dataset `df_ratings`, dilakukan pengecekan untuk mengetahui apakah ada pengguna `(User_Id)` yang memberi rating lebih dari sekali terhadap destinasi wisata `(Place_Id)` yang sama. Idealnya, setiap kombinasi user dan tempat harus unik."""

# Cek duplikat berdasarkan kombinasi User_Id dan Place_Id
duplicate_user_place = df_ratings[df_ratings.duplicated(['User_Id', 'Place_Id'], keep=False)]

print("Mengecek Duplikat User_Id dan Place_Id:")
duplicate_user_place

"""Hasil dari pengecekan menunjukkan bahwa:
- Tidak ditemukan duplikasi pada kolom `Place_Id` di dataset `df_tourism`, sehingga setiap destinasi wisata memiliki ID yang unik.
- Tidak ditemukan duplikasi pada kolom `Place_Name` di dataset `df_tourism`, menandakan bahwa nama destinasi juga tercatat secara unik.
- Pada dataset `df_ratings`, ditemukan sebanyak `798 baris duplikasi` pada kombinasi `User_Id` dan `Place_Id`, yang berarti beberapa pengguna memberikan lebih dari satu rating untuk destinasi yang sama.

#### **2.5.3. Cek Missing Value**

Selanjutnya, dilakukan pemeriksaan terhadap missing values dalam dataset. Nilai yang hilang dapat mempengaruhi hasil analisis maupun kinerja model rekomendasi, sehingga perlu diidentifikasi terlebih dahulu kolom mana saja yang mengandung data kosong.
"""

# Cek missing values untuk tourism_with_id.csv
print("Nissing values pada tourism_with_id.csv:")
print((df_tourism.isnull().sum()))
print("\n")

# Cek missing values untuk tourism_rating.csv
print("Missing values pada tourism_rating.csv:")
print((df_ratings.isnull().sum()))

"""Hasil dari pengecekan menunjukkan bahwa:
- Pada dataset `df_tourism`, terdapat missing values pada kolom `Time_Minutes` sebanyak 232 baris, dan seluruh baris pada kolom `Unnamed: 11` kosong.
- Sedangkan pada dataset `df_ratings`, tidak ditemukan missing values pada seluruh kolom.

#### **2.5.4. Cek Kolom Yang Tidak Relevan**

Dalam proses evaluasi data, penting untuk mengidentifikasi kolom-kolom yang tidak relevan atau redundan. Kolom yang tidak memuat informasi berguna atau hanya merupakan salinan dari kolom lain dapat menyebabkan redundansi dan memperbesar ukuran dataset secara tidak perlu. Oleh karena itu, perlu dilakukan pemeriksaan lebih lanjut sebelum memutuskan untuk menghapusnya.

Saat meninjau struktur dataset, ditemukan sebuah kolom tambahan bernama `Unnamed: 12` yang tampaknya tidak familiar dan sekilas terlihat mirip dengan `Place_Id`. Untuk mengetahui apakah kolom ini memuat informasi baru atau hanya merupakan salinan dari kolom yang sudah ada, kedua kolom ditampilkan secara berdampingan untuk dilakukan pemeriksaan lebih lanjut.
"""

df_tourism[['Place_Id', 'Unnamed: 12']]

"""Terlihat bahwa nilai-nilai pada kedua kolom tersebut tampak identik. Namun, untuk memastikan bahwa tidak terdapat perbedaan tersembunyi, dilakukan pengecekan lanjutan dengan membandingkan seluruh isi kedua kolom secara menyeluruh."""

# Cek apakah semua nilai di Place_Id dan Unnamed: 12 sama persis
(df_tourism['Place_Id'] == df_tourism['Unnamed: 12']).all()

"""Hasil dari pengecekan ini menghasilkan `True`, yang berarti seluruh nilai di `Unnamed: 12 memang 100% identik dengan Place_Id`. Dengan demikian, dapat disimpulkan bahwa kolom `Unnamed: 12` tidak memuat informasi baru dan dapat dihapus untuk menjaga kebersihan serta efisiensi data.

#### **2.5.5. Hasil Pengecekan Kondisi Data**

Berdasarkan hasil pengecekan, diperoleh temuan sebagai berikut:

- Kualitas Duplikasi

  - Dataset `df_tourism`
      
    - Tidak ditemukan data duplikat berdasarkan `Place_Id` maupun `Place_Name`, sehingga `seluruh data destinasi wisata bersifat unik` dan tidak memerlukan proses deduplikasi.

    - Selain itu, dilakukan pengecekan terhadap kolom `Place_Id` dan `Unnamed: 12`. Kolom `Unnamed: 12` memiliki isi yang identik dengan `Place_Id`, sehingga dapat dihapus karena redundan.

  - Dataset `df_ratings`

    Tidak ditemukan data duplikat pada kombinasi `User_Id` dan `Place_Id`. `Setiap pasangan user dan destinasi yang dirating dianggap unik`. Oleh karena itu, tidak diperlukan proses deduplikasi.

- Kualitas Missing Values

  - Dataset `df_tourism`

    Terdapat missing values pada kolom `Time_Minutes` sebanyak 232 baris, serta kolom `Unnamed: 11` yang seluruh isinya kosong (437 baris).

    - Kolom `Unnamed: 11` dapat dihapus karena seluruh data pada kolom ini kosong dan tidak mengandung informasi yang berguna.

    - Kolom `Time_Minutes` dapat dihapus Karena terdapat banyak missing values (232 baris) dan informasi waktu kunjungan ini tidak menjadi fokus utama dalam sistem rekomendasi berbasis rating.

  - Dataset `df_ratings`

    Tidak ditemukan missing values di seluruh kolom, sehingga tidak memerlukan langkah tambahan seperti imputasi atau penghapusan data.

---

## **3. Exploratory Data Analysis**

Exploratory data analysis merupakan proses investigasi awal pada data untuk menganalisis karakteristik, menemukan pola, anomali, dan memeriksa asumsi pada data. Teknik ini biasanya menggunakan bantuan statistik dan representasi grafis atau visualisasi.

### 3.1. Univariate Analysis
"""

def plot_kategori(df, feature, warna='purple'):
    """
    Menampilkan jumlah dan persentase kategori serta plot batang dari suatu kolom kategorikal.

    Parameters:
    df (DataFrame): DataFrame yang berisi data.
    feature (str): Nama kolom kategorikal.
    warna (str): Warna untuk bar chart (default = 'orange').
    """
    count = df[feature].value_counts()
    percent = 100 * df[feature].value_counts(normalize=True)
    df_summary = pd.DataFrame({
        'Jumlah Sampel': count,
        'Persentase (%)': percent.round(1)
    })

    print(f"\nRingkasan untuk kolom: {feature}")
    print(df_summary)
    print("\n")

    print("Visualisasi:")
    count.plot(kind='bar', title=feature, color=warna)
    plt.ylabel("Jumlah")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def plot_histogram_semua_kolom(df, bins=50, figsize=(12, 8), color='purple'):
    """
    Menampilkan histogram dari semua kolom numerik di dalam dataframe menggunakan seaborn.histplot.

    Parameters:
    df (DataFrame): DataFrame yang akan diplot.
    bins (int): Jumlah bin pada histogram.
    figsize (tuple): Ukuran figure.
    color (str): Warna histogram.
    """
    numeric_cols = df.select_dtypes(include=['number']).columns
    n_cols = len(numeric_cols)
    n_rows = (n_cols + 2) // 3  # 3 kolom per baris

    plt.figure(figsize=figsize)
    for i, col in enumerate(numeric_cols, 1):
        plt.subplot(n_rows, 3, i)
        sns.histplot(df[col], bins=bins, kde=True, color=color)
        plt.title(f'Histogram: {col}')
        plt.xlabel(col)
        plt.ylabel('Frekuensi')
        plt.tight_layout()
    plt.show()

def compare_user_vs_aggregated_ratings(df_tourism, df_ratings):
    """
    Menampilkan ringkasan kategori dan visualisasi perbandingan antara
    rating pengguna vs rating agregat dari dataset df_tourism.

    Parameter:
    - df_tourism: DataFrame berisi data destinasi wisata dan rating agregat
    - df_ratings: DataFrame berisi data rating dari pengguna (Place_Id, Place_Ratings)
    """

    # Hitung rata-rata rating dari pengguna
    df_user_rating = df_ratings.groupby('Place_Id')['Place_Ratings'].mean().reset_index()
    df_user_rating.rename(columns={'Place_Ratings': 'User_Avg_Rating'}, inplace=True)

    # Gabungkan dengan rating asli dari df_tourism
    df_compare = pd.merge(df_tourism[['Place_Id', 'Place_Name', 'Rating']], df_user_rating, on='Place_Id')

    # Ambil beberapa destinasi untuk ditampilkan agar tidak terlalu padat
    df_compare = df_compare.sort_values(by='User_Avg_Rating', ascending=False).head(20)

    # Print ringkasan kategori
    category_summary = df_tourism['Category'].value_counts().reset_index()
    category_summary.columns = ['Category', 'Jumlah Sampel']
    category_summary['Persentase (%)'] = round(
        100 * category_summary['Jumlah Sampel'] / category_summary['Jumlah Sampel'].sum(), 1
    )

    print("Ringkasan untuk kolom: Category")
    print(category_summary.set_index('Category'))

    print("\nVisualisasi:")

    # Visualisasi perbandingan rating
    sns.set(style="whitegrid")
    plt.figure(figsize=(12, 8))

    bar_width = 0.4
    x = np.arange(len(df_compare))

    plt.bar(x, df_compare['User_Avg_Rating'], width=bar_width, label='Rata-rata Rating Pengguna', color='skyblue')
    plt.bar(x + bar_width, df_compare['Rating'], width=bar_width, label='Rating Asli (df_tourism)', color='orange')

    plt.xlabel('Destinasi Wisata')
    plt.ylabel('Rating')
    plt.title('Perbandingan Rating Pengguna vs Rating Asli Destinasi')
    plt.xticks(x + bar_width / 2, df_compare['Place_Name'], rotation=45, ha='right')
    plt.legend()
    plt.tight_layout()
    plt.show()

"""#### 3.1.1. Numerical Features

##### **a. Analisis Rating (dari df_tourism)**

Fitur `Rating` pada dataset `df_tourism` mencerminkan skor destinasi wisata yang tampaknya berasal dari sistem eksternal atau sumber agregator. Nilai Rating ini relatif tinggi dan tidak bervariasi banyak, dengan mayoritas destinasi memiliki rating di kisaran 4.3–4.6.

Distribusi rating-nya menunjukkan bahwa:
- Rating 4.4 dan 4.5 adalah yang paling umum (masing-masing 22.4%).
- Rating sangat tinggi seperti 5.0 hanya muncul sebanyak 4 kali (0.9%).
- Tidak ada nilai rating di bawah 3.4, sehingga semua destinasi dianggap cukup baik secara umum.
"""

plot_kategori(df_tourism, 'Rating')

"""Hal ini mengindikasikan bahwa fitur `Rating` pada `df_tourism` mungkin kurang informatif untuk merefleksikan perbedaan nyata dalam kualitas destinasi, dan bisa jadi terlalu bias ke arah positif.

##### **b. Analisis Rating (dari df_ratings)**

Sebaliknya, fitur `Place_Ratings` dari dataset `df_ratings` yang berisi input dari pengguna memperlihatkan variasi rating yang lebih seimbang:
- Nilai 4, 3, dan 2 masing-masing menyumbang lebih dari 20% data.
- Nilai 5 sedikit lebih rendah (20.2%), sementara nilai 1 muncul sebanyak 17.1%.
- Distribusi ini cenderung menyerupai distribusi rating pengguna pada umumnya yang lebih subjektif dan beragam.
"""

plot_kategori(df_ratings, 'Place_Ratings')

"""Dengan persebaran yang lebih bervariasi, fitur `Place_Ratings` lebih cocok digunakan sebagai dasar dalam sistem rekomendasi berbasis collaborative filtering karena mencerminkan pengalaman dan penilaian pengguna secara langsung.

##### c. Analisis Perbandingan Rating Asli dan Rata-rata Rating Pengguna

Fitur `Rating` pada dataset `df_tourism` mencerminkan skor destinasi wisata dari sumber eksternal atau sistem agregator, sementara `User_Avg_Rating` dihitung berdasarkan rata-rata penilaian pengguna pada dataset `df_ratings`.

Perbandingan ini menunjukkan bahwa:
- Secara umum, rating dari pengguna cenderung mendekati atau sedikit lebih rendah dibandingkan rating asli dari dataset, meskipun tidak terlalu signifikan.
- Seluruh destinasi yang dianalisis memiliki nilai rating tinggi di atas 4.0, baik dari versi agregat maupun versi pengguna.
- Tidak ditemukan outlier mencolok antara kedua jenis rating, yang menunjukkan bahwa persepsi pengguna terhadap kualitas destinasi cenderung sejalan dengan sistem rating eksternal.
"""

compare_user_vs_aggregated_ratings(df_tourism, df_ratings)

"""Namun demikian, karena rating asli (Rating) memiliki rentang yang sangat sempit dan mayoritas destinasi memiliki nilai hampir seragam (antara 4.3–4.6), hal ini membuat fitur tersebut kurang mampu mencerminkan variasi nyata dalam persepsi kualitas destinasi. Sebaliknya, rata-rata rating pengguna dapat memberikan alternatif indikator yang lebih variatif karena mencerminkan pengalaman aktual.

##### **d. Analisis Distribusi Fitur Numerik**
"""

plot_histogram_semua_kolom(df_tourism)

"""Analisis ini bertujuan untuk memahami pola distribusi dari setiap fitur numerik dalam dataset `df_tourism`. Visualisasi berupa histogram dan kurva KDE (Kernel Density Estimation) memberikan gambaran awal terhadap penyebaran dan bentuk distribusi data.
- Fitur `Place_Id` dan `Unnamed: 12` memiliki distribusi yang identik dan menyerupai distribusi seragam. Hal ini mengindikasikan bahwa ID tempat diberikan secara merata tanpa ada kecenderungan klaster atau lonjakan nilai tertentu. Kemungkinan besar `Unnamed: 12` merupakan duplikat dari `Place_Id` dan perlu dihapus dalam tahap praproses data.
- Distribusi harga `(Price)` sangat miring ke kanan `(right-skewed)`, dengan mayoritas nilai terkonsentrasi di bawah Rp 100.000. Terdapat outlier dengan harga sangat tinggi (> Rp 800.000). Distribusi ini menunjukkan bahwa sebagian besar tempat wisata cenderung berbiaya rendah atau gratis, sementara hanya sebagian kecil yang memiliki harga tinggi.
- Distribusi `Rating` mendekati distribusi normal dengan puncak pada nilai 4.4–4.6. Hal ini menunjukkan bahwa sebagian besar tempat wisata mendapatkan penilaian yang cukup tinggi dari pengunjung. Tidak terdapat nilai ekstrim di bawah 3.5 atau di atas 5, yang menandakan data rating relatif bersih dan stabil.
- Distribusi waktu kunjungan `(Time_Minutes)` juga menunjukkan distribusi `miring ke kanan`. Sebagian besar wisatawan menghabiskan waktu kurang dari 100 menit di lokasi, dengan sebagian kecil menghabiskan lebih dari 200 menit. Pola ini umum terjadi karena banyak wisata bersifat singkat (seperti taman atau pantai) yang tidak membutuhkan durasi kunjungan panjang.
- Distribusi nilai `Lat` (latitude) dan `Long` (longitude) menunjukkan konsentrasi geografis lokasi wisata. `Lat` berkisar antara -8 hingga -6 derajat, mengindikasikan mayoritas tempat wisata berada di wilayah selatan Indonesia (seperti Pulau Jawa atau Bali). `Long` terkonsentrasi antara 106 hingga 112 derajat, yang juga mendukung interpretasi bahwa data banyak berasal dari daerah di sekitar Pulau Jawa dan sekitarnya. Kedua fitur ini tidak memiliki distribusi normal, karena mereka merepresentasikan lokasi geografis yang bergantung pada posisi fisik dan bukan hasil pengukuran acak.
- Fitur `Unnamed: 11` sepenuhnya kosong (hanya menunjukkan frekuensi 0 pada semua nilai). Ini merupakan kolom tidak relevan yang kemungkinan berasal dari hasil ekspor CSV dan perlu dihapus pada tahap pembersihan data.

#### 3.1.2 Categorical Features

##### **a. Analisis Kategori Destinasi Wisata (Category dari `df_tourism`)**

Fitur `Category` pada dataset `df_tourism` merepresentasikan jenis atau klasifikasi dari masing-masing destinasi wisata. Fitur ini penting untuk memahami preferensi pengguna terhadap tipe-tipe tempat yang berbeda serta membantu dalam proses segmentasi maupun filtering konten rekomendasi.

Distribusi kategorinya menunjukkan bahwa:
- Taman Hiburan merupakan kategori terbanyak, mencakup 30.9% dari total data.
- Disusul oleh kategori Budaya (26.8%) dan Cagar Alam (24.3%), yang juga cukup dominan.
- Kategori Bahari memiliki porsi lebih kecil (10.8%).
- Sementara itu, kategori Tempat Ibadah (3.9%) dan Pusat Perbelanjaan (3.4%) hanya mewakili sebagian kecil dari data.
"""

plot_kategori(df_tourism, 'Category')

"""Hal ini mengindikasikan bahwa fitur `Category` memiliki distribusi yang tidak seimbang. Dominasi beberapa kategori besar (seperti Taman Hiburan) dapat menyebabkan bias dalam sistem rekomendasi. Msalnya, sistem cenderung menyarankan destinasi dari kategori mayoritas. Oleh karena itu, mungkin diperlukan strategi penyeimbangan atau pembobotan kategori untuk menghasilkan rekomendasi yang lebih beragam dan adil.

##### **b. Analisis Kota Destinasi Wisata Berada (City dari `df_tourism`)**

Fitur `City` pada dataset `df_tourism` merepresentasikan lokasi geografis dari masing-masing destinasi wisata. Fitur ini penting dalam konteks sistem rekomendasi karena dapat memengaruhi preferensi pengguna, terutama dalam skenario berbasis lokasi atau personalisasi regional.

Distribusi kota menunjukkan bahwa:
- Yogyakarta (28.8%) dan Bandung (28.4%) merupakan dua kota dengan jumlah destinasi terbanyak, bersama-sama menyumbang lebih dari 57% dari total data.
- Diikuti oleh Jakarta (19.2%), Semarang (13.0%), dan Surabaya (10.5%) yang jumlahnya relatif lebih rendah.

Tidak terdapat kota lain di luar lima tersebut dalam dataset, sehingga distribusi ini cukup terfokus pada wilayah tertentu.
"""

plot_kategori(df_tourism, 'City')

"""Hal ini mengindikasikan bahwa fitur `City` memiliki distribusi yang cukup berat ke kota-kota tertentu. Jika tidak diimbangi, sistem rekomendasi berpotensi hanya menyarankan destinasi dari kota-kota dominan. Oleh karena itu, penting untuk mempertimbangkan diversifikasi lokasi, terutama jika sistem bertujuan menyediakan rekomendasi lintas daerah atau bagi pengguna dengan mobilitas tinggi.

##### **c. Analisis Nama Destinasi Wisata (Place_Name dari `df_tourism`)**

Fitur `Place_Name` pada dataset `df_tourism` merepresentasikan nama destinasi wisata yang unik. Untuk keperluan eksplorasi lebih lanjut, analisis dilakukan terhadap sepuluh destinasi dengan jumlah rating terbanyak berdasarkan data `df_ratings`.

Distribusi popularitasnya menunjukkan bahwa:
- Gunung Lalakon dan Pantai Parangtritis merupakan dua tempat wisata dengan jumlah rating terbanyak, masing-masing sebanyak 39 kali (0.4% dari total data).
- Tempat wisata lain seperti Gereja Perawan Maria Tak Berdosa Surabaya, Pantai Kesirat, dan Taman Sungai Mudal juga berada di urutan teratas dengan kontribusi yang serupa.
- Masing-masing dari 10 tempat terpopuler hanya menyumbang kurang dari 0.5% dari total keseluruhan rating, menandakan bahwa data rating tersebar cukup merata di antara banyak destinasi.
"""

# Hitung jumlah rating untuk setiap Place_Id
top_10 = df_ratings['Place_Id'].value_counts().reset_index()[0:10]
# Ganti nama kolom biar jelas
top_10.columns = ['Place_Id', 'Rating_Count']
# Gabungkan dengan nama tempat dari df_tourism
top_10 = pd.merge(top_10, df_tourism[['Place_Id', 'Place_Name']], on='Place_Id', how='left')

# Hitung persentase
total_rating = df_ratings['Place_Id'].count()
top_10['Persentase (%)'] = round(100 * top_10['Rating_Count'] / total_rating, 1)

# Tampilkan ringkasan
print("\n Ringkasan 10 Tempat Wisata dengan Rating Terbanyak:")
print(top_10[['Place_Name', 'Rating_Count', 'Persentase (%)']])
print("\n")

# Visualisasi wisata dengan jumlah rating terbanyak
plt.figure(figsize=(10,6))
sns.barplot(x='Rating_Count', y='Place_Name', data=top_10, palette='mako')
plt.title('10 Tempat Wisata dengan Rating Terbanyak')
plt.xlabel('Jumlah Rating')
plt.ylabel('Nama Lokasi')
plt.tight_layout()
plt.show()

"""Hal ini mengindikasikan bahwa tidak ada satu tempat wisata yang secara dominan mendominasi interaksi pengguna dalam hal rating. Ini bisa menjadi indikasi sistem yang sehat, namun juga menunjukkan bahwa model rekomendasi perlu memperhatikan konteks personalisasi atau atribut lain (seperti kategori atau lokasi), karena hanya mengandalkan popularitas berdasarkan jumlah rating tidak cukup untuk membedakan secara signifikan antar destinasi.

---

## **4. Data Preparation**

Pada tahap data preparation, dilakukan serangkaian langkah untuk memastikan bahwa data yang digunakan dalam proses pemodelan bersih, terstruktur, dan siap untuk dianalisis. Tahapan ini mencakup pembersihan data, penggabungan dataset, pengolahan teks, encoding variabel kategorikal, normalisasi rating, dan pembagian data menjadi set pelatihan dan pengujian.

### 4.1. Menghapus Kolom Yang Tidak Diperlukan

Untuk menyederhanakan struktur data serta memastikan hanya informasi yang relevan digunakan dalam proses analisis dan pengembangan sistem rekomendasi, dilakukan penghapusan terhadap beberapa kolom yang dinilai tidak memiliki kontribusi signifikan. Proses ini menggunakan perintah:
"""

# Membuang kolom yang tidak dipakai
df_tourism_cleaned = df_tourism.drop(['City', 'Price', 'Time_Minutes', 'Coordinate', 'Lat', 'Long', 'Unnamed: 11', 'Unnamed: 12'],axis=1)

# Menampilkan daftar kolom setelah penghapusan untuk memverifikasi bahwa kolom-kolom yang tidak diperlukan telah dihapus
print("\nKolom setelah penghapusan:")
df_tourism_cleaned.columns

"""Pertimbangan penghapusan kolom adalah sebagai berikut:

- Kolom `Time_Minutes` memiliki jumlah nilai yang hilang cukup besar, yakni sebanyak 232 baris, sehingga dianggap kurang representatif untuk dianalisis lebih lanjut.
- `Unnamed: 11` merupakan kolom kosong tanpa informasi yang berguna, sehingga dikeluarkan dari dataset.
- Kolom seperti `City`, `Price`, `Coordinate`, `Lat`, dan `Long` juga dihapus karena pendekatan yang digunakan bersifat berbasis konten (content-based) dengan fokus pada analisis teks dari deskripsi dan kategori. Kolom-kolom tersebut tidak memberikan kontribusi langsung terhadap representasi semantik yang dianalisis melalui cosine similarity. Namun, kolom-kolom ini tetap dapat dipertimbangkan untuk pengembangan sistem berbasis konteks lokasi atau harga di masa mendatang.

Hasil dari proses ini disimpan dalam variabel baru bernama `df_tourism_cleaned`, yang berisi versi dataset yang telah disederhanakan dan dibersihkan. Untuk memverifikasi hasil penghapusan, kolom-kolom dalam dataset tersebut ditampilkan melalui `df_tourism_cleaned.head()`.
"""

df_tourism_cleaned.head()

"""### 4.2. Menghapus Data Yang Duplikat

Untuk menjaga integritas serta konsistensi data selama proses analisis dan pemodelan, seluruh baris yang teridentifikasi sebagai duplikat dihapus dari dataset menggunakan fungsi `drop_duplicates()`. Langkah ini penting dilakukan guna menghindari bias dan distorsi hasil analisis yang dapat muncul akibat data ganda.

Setelah proses penghapusan, dilakukan verifikasi ulang untuk memastikan bahwa tidak ada lagi baris duplikat yang tersisa dalam dataset.
"""

# Mengecek dan menghapus duplikasi pada dataset df_ratings
print("Jumlah Duplikasi pada df_ratings Sebelum Dihapus:", df_ratings.duplicated().sum())

# Menghapus duplikasi
df_ratings = df_ratings.drop_duplicates()

# Mengecek kembali setelah penghapusan
print("Jumlah Duplikasi pada df_ratings Setelah Dihapus:", df_ratings.duplicated().sum())

# Mengecek dan menghapus duplikasi pada dataset df_tourism_cleaned
print("Jumlah Duplikasi pada df_tourism_cleaned Sebelum Dihapus:", df_tourism_cleaned.duplicated().sum())

# Menghapus duplikasi
df_tourism_cleaned = df_tourism_cleaned.drop_duplicates()

# Mengecek kembali setelah penghapusan
print("Jumlah Duplikasi pada df_tourism_cleaned Setelah Dihapus:", df_tourism_cleaned.duplicated().sum())

"""Dengan tidak adanya duplikasi yang tersisa, dataset kini berada dalam kondisi yang lebih bersih dan siap untuk digunakan dalam tahap analisis lebih lanjut maupun pembangunan sistem rekomendasi.

### 4.3. Menggabungkan Dataset

Setelah proses pembersihan dilakukan pada kedua dataset, langkah selanjutnya adalah menggabungkan informasi dari data rating pengguna `(df_ratings)` dengan data destinasi wisata yang telah dibersihkan `(df_tourism_cleaned)`. Tujuan dari penggabungan ini adalah untuk membentuk dataset rekomendasi yang menyajikan informasi rata-rata rating dari setiap destinasi wisata berdasarkan data yang diberikan oleh pengguna.

Penggabungan dilakukan melalui langkah-langkah berikut:
- Menghitung Rata-rata Rating

    Dataset df_ratings dikelompokkan berdasarkan kolom Place_Id, kemudian dihitung rata-rata dari kolom Place_Ratings untuk setiap destinasi. Proses ini menghasilkan dataframe baru yang berisi dua kolom: Place_Id dan Place_Ratings.

- Penggabungan Dataset

    Rata-rata rating yang telah dihitung kemudian digabungkan dengan dataset df_tourism_cleaned menggunakan fungsi pd.merge() dengan parameter on='Place_Id'. Penggabungan dilakukan berdasarkan kolom Place_Id yang merupakan kunci unik bagi setiap destinasi wisata.
"""

df_recommendation = pd.merge(
    # Hitung rata-rata rating untuk setiap destinasi berdasarkan 'Place_Id'.
    df_ratings.groupby('Place_Id')['Place_Ratings'].mean().reset_index(),

    # Gabungkan dengan data destinasi wisata yang sudah dibersihkan.
    df_tourism_cleaned,

    # Lakukan penggabungan berdasarkan kolom 'Place_Id' yang sama di kedua dataset.
    on='Place_Id'
)

"""Hasil akhir dari proses ini adalah dataframe `df_recommendation` yang menyatukan informasi deskriptif destinasi wisata dengan nilai rata-rata rating dari pengguna, dan siap digunakan sebagai basis sistem rekomendasi."""

# Cek jumlah string kosong pada kolom 'Description' dan 'Category'
empty_description = (df_recommendation['Description'].str.strip() == '').sum()
empty_category = (df_recommendation['Category'].str.strip() == '').sum()

# Tangani missing values hanya jika memang ada NaN
if df_recommendation['Description'].isnull().any():
    df_recommendation['Description'] = df_recommendation['Description'].fillna('')

if df_recommendation['Category'].isnull().any():
    df_recommendation['Category'] = df_recommendation['Category'].fillna('')


print(f"Jumlah string kosong pada kolom 'Description': {empty_description}")
print(f"Jumlah string kosong pada kolom 'Category': {empty_category}")

# Cek apakah ada destinasi dengan 'Place_Name' yang sama (duplikat) setelah penggabungan.
if df_recommendation['Place_Name'].duplicated().any():
    print("Peringatan: Terdapat 'Place_Name' yang duplikat.")

# Tampilkan beberapa baris pertama dari dataset hasil penggabungan untuk memverifikasi hasilnya.
print("\nData Rekomendasi setelah penggabungan (Train Data):")
display(df_recommendation)

"""### 4.4. Persiapan Data (Content Based Filtering)

#### 4.4.1. Preprocessing Text

Dalam `sistem rekomendasi berbasis konten (content-based)`, kualitas representasi teks sangat berpengaruh terhadap akurasi hasil yang diberikan. Oleh karena itu, dilakukan tahapan pra-pemrosesan data teks untuk `memastikan bahwa informasi yang digunakan oleh model benar-benar relevan dan bermakna`. Langkah-langkah ini bertujuan `untuk mengurangi kebisingan (noise) pada data`, `menyatukan variasi kata yang memiliki arti sama`, serta `memperkaya konteks antar fitur`.

Untuk mendapatkan representasi teks yang lebih bersih dan bermakna, dilakukan beberapa langkah pembersihan data:
- `Penggabungan Fitur`: Menggabungkan informasi dari kolom `deskripsi` dan `kategori destinasi wisata` menjadi satu kolom teks baru untuk memperkaya konteks.
- `Normalisasi Teks`: Mengubah seluruh teks menjadi huruf kecil `(lowercase)` agar seragam.
- `Stemming dan Stopword Removal`: Menggunakan library Sastrawi untuk menghilangkan kata-kata umum yang tidak bermakna `(stopwords)` dan mengembalikan kata ke bentuk dasarnya `(stemming)`, sehingga `meminimalkan variasi kata yang tidak perlu`.

Kata-kata dalam Bahasa Indonesia ditangani menggunakan pustaka `Sastrawi` yang menyediakan fungsi stemming dan stopword removal.
- `Stemming` digunakan untuk mengubah kata ke bentuk dasarnya, sehingga kata-kata seperti “berkunjung”, “mengunjungi”, dan “kunjungan” akan disederhanakan menjadi “kunjung”.
- `Stopword removal` digunakan untuk menghapus kata-kata umum yang tidak memiliki makna signifikan seperti “dan”, “di”, atau “yang”.
"""

# Menginisialisasi objek stemmer dan stopword remover dari pustaka Sastrawi

stemmer = StemmerFactory().create_stemmer()  # Untuk melakukan stemming
stopword = StopWordRemoverFactory().create_stop_word_remover()  # Untuk menghapus stopwords

"""Dengan fungsi `preprocessing()` digunakan untuk mengubah teks menjadi huruf kecil, melakukan stemming, serta menghapus stopwords secara otomatis."""

def preprocessing(text):
    """
    Melakukan preprocessing teks dengan mengubah ke lowercase, stemming, dan menghapus stopwords.

    Parameters:
    - text (str): Teks yang akan diproses.

    Returns:
    - str: Teks yang telah diproses.
    """
    text = text.lower()  # Mengubah semua huruf menjadi lowercase
    text = stemmer.stem(text)  # Melakukan stemming untuk mengubah kata ke bentuk dasar
    text = stopword.remove(text)  # Menghapus stopwords dari teks
    return text

"""`Deskripsi` dan `kategori` tempat memberikan dua jenis informasi yang saling melengkapi: `deskripsi` memberikan gambaran naratif, sedangkan `kategori` menunjukkan klasifikasi destinasi. Kedua informasi tersebut kemudian digabungkan ke dalam satu kolom baru bernama `Tags`. Kolom ini menyatukan aspek naratif dan kategorikal untuk memperkaya konteks tiap destinasi.

Selanjutnya, kolom `Tags` menjalani tahap preprocessing berupa normalisasi teks, pembersihan, dan penyederhanaan agar dapat direpresentasikan dalam bentuk numerik yang dapat dipahami oleh mesin.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Menggabungkan kolom 'Description' dan 'Category' menjadi satu kolom 'Tags'
# df_recommendation['Tags'] = df_recommendation['Description'] + ' ' + df_recommendation['Category']
# 
# # Menerapkan preprocessing pada kolom 'Tags'
# df_recommendation['Tags'] = df_recommendation['Tags'].apply(preprocessing)

df_recommendation.head()

"""Proses preprocessing juga diterapkan secara terpisah pada kolom `Description`. Tujuannya adalah untuk memungkinkan analisis perbandingan antara representasi teks gabungan `(Description + Category)` dengan representasi yang hanya berasal dari deskripsi. Pendekatan ini bertujuan untuk mengevaluasi sejauh mana informasi dari kategori berkontribusi terhadap peningkatan relevansi hasil rekomendasi."""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Preprocessing pada kolom 'Description' saja dan menyimpannya dalam kolom 'Description_Preprocessed'
# df_recommendation['Description_Preprocessed'] = df_recommendation['Description'].apply(preprocessing)
# 
# df_recommendation.head()

"""Karena `proses ini cukup memakan waktu`, dataset yang telah diproses disimpan dalam sebuah file CSV. Langkah ini dilakukan untuk menghindari pengulangan proses yang sama saat melakukan eksperimen lanjutan. Dengan demikian, data yang digunakan sudah dalam kondisi bersih dan siap untuk digunakan pada tahap pelatihan model."""

# Menyimpan Dataset Setelah Preprocessing
df_recommendation.to_csv('data_recommendation_preprocessed.csv', index=False)

"""#### 4.4.2. Ekstraksi Fitur Teks Menggunakan TF-IDF

Untuk membangun `sistem rekomendasi berbasis Content-Based Filtering`, digunakan representasi numerik dari data teks yang bertujuan menangkap karakteristik unik dari setiap destinasi wisata. Salah satu pendekatan yang diterapkan adalah `TF-IDF (Term Frequency–Inverse Document Frequency)`, yaitu teknik populer yang digunakan untuk mengukur tingkat kepentingan suatu kata dalam sebuah dokumen relatif terhadap keseluruhan korpus.



Dalam penerapannya, skor dalam TF-IDF digunakan untuk mengidentifikasi istilah-istilah yang mengandung informasi penting dalam dokumen tertentu. Proses ini dapat diimplementasikan menggunakan fungsi `TfidfVectorizer()` dari library `scikit-learn`. Fungsi tersebut akan melakukan tokenisasi pada teks, mempelajari kosa kata, membobotkan frekuensi dokumen secara terbalik (inverse), dan memungkinkan pengguna untuk melakukan encoding teks baru.

Dalam sistem ini, `TF-IDF diterapkan pada dua jenis sumber teks yang berbeda`, yakni kolom `Tags` dan `Description_Preprocessed`. Keduanya diproses dalam dua skenario berbeda untuk melihat pengaruh masing-masing terhadap hasil rekomendasi. Adapun tahapan-tahapan yang dilakukan adalah sebagai berikut:
- Inisialisasi TfidfVectorizer
- Perhitungan IDF dan Pembentukan Matriks TF-IDF
- Mapping Fitur ke Nama yang Terbaca
- Visualisasi dan Pemeriksaan Matriks TF-IDF

##### **a. Kolom `Tags`**

Proses representasi teks dimulai dengan penggunaan `TfidfVectorizer`, yang diterapkan untuk mengekstrak kata-kata penting dari kolom `Tags`, yang berisi `kombinasi deskripsi dan kategori destinasi`. Pada tahap ini, `TfidfVectorizer()` digunakan untuk `mengidentifikasi korelasi antara berbagai istilah dalam tag`, dengan mempertimbangkan frekuensi kemunculan kata dalam masing-masing dokumen (destinasi) dan pentingnya kata tersebut dalam keseluruhan dataset. Teknik ini memungkinkan untuk menggali informasi relevan yang dapat digunakan untuk membangun sistem rekomendasi berbasis Content-Based Filtering.
"""

# Inisialisasi TfidfVectorizer untuk kolom 'Tags'
tv_tags = TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=2)

# Melakukan perhitungan IDF pada data Tags
tv_tags.fit(df_recommendation['Tags'])

# Menampilkan daftar fitur yang diekstrak dari kolom Tags
pd.DataFrame(tv_tags.get_feature_names_out(), columns=['Tags'])

"""Selanjutnya, proses `fit` dilakukan pada kolom `Tags`, diikuti dengan transformasi untuk mengubah data teks menjadi matriks representasi numerik. Matriks ini berisi skor TF-IDF untuk setiap kata dalam tag yang terdapat pada setiap destinasi."""

# Melakukan fit pada kolom 'Tags' lalu ditransformasikan ke bentuk matrix
vectors_tags = tv_tags.fit_transform(df_recommendation['Tags'])

# Melihat ukuran matrix vectors_tags
vectors_tags.shape

"""Dapat dilihat bahwa matriks yang dihasilkan berukuran `(437, 5000)`. Angka `437` menunjukkan `jumlah entri data`, yaitu destinasi wisata yang ada dalam dataset, sementara `angka 5000` mewakili `jumlah fitur`, yaitu kata-kata penting yang diekstrak dari kombinasi deskripsi dan kategori destinasi wisata. Fitur-fitur ini `mencerminkan istilah-istilah yang memiliki bobot TF-IDF tertinggi dan relevansi` dalam konteks sistem rekomendasi.

Untuk menghasilkan vektor `vectors_tags` dalam bentuk matriks, fungsi `todense()` dapat digunakan untuk mengubah hasil transformasi menjadi matriks padat yang lebih mudah dibaca dan dianalisis.
"""

vectors_tags.todense()

"""Hasilnya akan berupa matriks yang menggambarkan skor TF-IDF untuk setiap kata yang terdapat dalam setiap destinasi, dengan nilai nol pada posisi yang menunjukkan ketidakhadiran kata tersebut dalam tag destinasi. Matriks ini memudahkan dalam visualisasi dan analisis data lebih lanjut.

Selanjutnya, akan ditinjau matriks `vectors_tags` yang merepresentasikan kata-kata penting dari hasil penggabungan `deskripsi` dan `kategori` destinasi.
"""

df_sample_tags = pd.DataFrame(
    vectors_tags.todense(),
    columns = tv_tags.get_feature_names_out(),
    index = df_recommendation.Place_Name
).sample(50, axis=1).sample(20, axis=0)

# Tampilkan dengan scroll horizontal
display(HTML(df_sample_tags.to_html(notebook=True, escape=False)))

"""Output matriks TF-IDF di atas menunjukkan representasi kata-kata penting dalam deskripsi dan kategori masing-masing destinasi wisata. Terlihat pada `Museum Sonobudoyo Unit I` memiliki nilai tertinggi `(0.134814	)` pada kata `"museum juga"`, yang mengindikasikan bahwa kata tersebut cukup penting dalam deskripsi atau kategorinya. Hal ini menunjukkan bahwa deskripsi destinasi tersebut kemungkinan menekankan identitasnya sebagai museum dan keberadaan fitur tambahan lainnya, sehingga kata "juga" muncul dalam konteks membandingkan atau menambahkan informasi.

Sebaliknya, sebagian besar destinasi lain seperti `Semarang Contemporary Art Gallery`, `Benteng Pendem`, hingga `Hutan Wisata Tinjomoyo Semarang` memiliki nilai nol pada kata-kata yang ditampilkan, yang menandakan bahwa kata-kata tersebut tidak dianggap penting untuk destinasi tersebut berdasarkan hasil vektorisasi TF-IDF.

Nilai-nilai TF-IDF ini mencerminkan seberapa relevan suatu kata terhadap suatu destinasi dalam korpus data secara keseluruhan. Dengan demikian, kata-kata kunci yang khas dapat diidentifikasi di tiap destinasi dan digunakan dalam proses content-based recommendation.

##### **b. Kolom `Description_Preprocessed`**

Sebelumnya, proses representasi teks telah diterapkan pada kolom `Tags`, yang merupakan hasil kombinasi antara deskripsi dan kategori destinasi wisata. Dengan menerapkan `TfidfVectorizer`, setiap destinasi direpresentasikan dalam bentuk vektor berdasarkan pentingnya kata-kata dalam kolom gabungan tersebut, yang kemudian dapat dimanfaatkan dalam sistem rekomendasi berbasis konten.

Sebagai langkah lanjutan, representasi teks kini difokuskan secara khusus pada kolom `Description_Preprocessed`, yang berisi deskripsi asli dari destinasi wisata setelah melalui tahap praproses. Berbeda dengan `Tags`, kolom ini mencerminkan narasi murni tanpa tambahan informasi kategori, sehingga memungkinkan eksplorasi lebih dalam terhadap pengalaman, suasana, dan karakteristik unik yang disampaikan melalui deskripsi.

Penerapan `TfidfVectorizer` pada kolom ini bertujuan untuk mengekstraksi kata-kata penting yang benar-benar muncul secara alami dalam deskripsi. Hasil vektorisasi ini memberikan perspektif tambahan bagi sistem rekomendasi, sehingga dapat mengidentifikasi kemiripan antar destinasi berdasarkan konten deskriptif yang lebih autentik dan tidak terpengaruh oleh label kategori eksplisit.
"""

# Inisialisasi TfidfVectorizer untuk kolom 'Description_Preprocessed'
tv_desc = TfidfVectorizer(max_features=5000, ngram_range=(1,2), min_df=2)

# Melakukan perhitungan IDF pada data `Description_Preprocessed`
tv_desc.fit(df_recommendation['Description_Preprocessed'])

# Menampilkan daftar fitur yang diekstrak dari kolom description_features
pd.DataFrame(tv_desc.get_feature_names_out(), columns=['description_features'])

"""Selanjutnya, proses `fit` dilakukan pada kolom `Description_Preprocessed`, diikuti dengan transformasi untuk mengubah data teks menjadi matriks representasi numerik. Matriks ini berisi skor TF-IDF untuk setiap kata dalam deskripsi yang terdapat pada setiap destinasi."""

# Melakukan fit pada kolom 'Description_Preprocessed' lalu ditransformasikan ke bentuk matrix
vectors_desc = tv_desc.fit_transform(df_recommendation['Description_Preprocessed'])

# Melihat ukuran matrix vectors_desc
vectors_desc.shape

"""Dapat dilihat bahwa matriks yang dihasilkan berukuran `(437, 5000)`. `Angka 437` menunjukkan `jumlah entri data`, yaitu destinasi wisata yang ada dalam dataset, sementara `angka 5000` mewakili `jumlah fitur`, yaitu kata-kata penting yang diekstrak dari deskripsi destinasi wisata. Fitur-fitur ini mencerminkan istilah-istilah yang memiliki bobot TF-IDF tertinggi dan relevansi dalam konteks sistem rekomendasi.

Untuk menghasilkan vektor `vectors_desc` dalam bentuk matriks, kita dapat menggunakan fungsi `todense()`. Fungsi ini mengubah hasil transformasi menjadi matriks padat yang lebih mudah dibaca dan dianalisis.
"""

vectors_desc.todense()

"""Hasilnya akan berupa matriks yang menggambarkan skor TF-IDF untuk setiap kata yang terdapat dalam setiap destinasi, dengan nilai nol pada posisi yang menunjukkan ketidakhadiran kata tersebut dalam deskripsi destinasi wisata. Matriks ini memudahkan dalam visualisasi dan analisis data lebih lanjut.

Selanjutnya, akan ditinjau matriks `vectors_desc` yang merepresentasikan kata-kata penting dari deskripsi destinasi wisata.
"""

df_sample_desc = pd.DataFrame(
    vectors_desc.todense(),
    columns=tv_desc.get_feature_names_out(),
    index=df_recommendation.Place_Name
).sample(50, axis=1).sample(20, axis=0)

# Tampilkan dengan scroll horizontal
display(HTML(df_sample_desc.to_html(notebook=True, escape=False)))

"""Output matriks TF-IDF di atas menunjukkan representasi numerik dari istilah-istilah penting yang muncul dalam kolom `Description_Preprocessed`, yang berisi deskripsi murni destinasi wisata. Setiap baris mewakili sebuah destinasi, sementara kolom menunjukkan nilai bobot TF-IDF dari kata-kata yang dianggap penting dalam deskripsi destinasi tersebut.

Sebagai contoh, pada baris `"Stone Garden Citatah"`, tampak bahwa kata `"garden	"` memiliki bobot TF-IDF sebesar `0.240593`, yang mengindikasikan bahwa kata tersebut memiliki signifikansi khusus dalam deskripsi destinasi ini dibandingkan dengan destinasi lainnya. Kemungkinan karena kata "garden" menjadi ciri khas utama dari nama dan konteks wisatanya. Hal serupa terlihat pada `"Ocean Ecopark"`, di mana kata `"ancol"` memiliki bobot TF-IDF sebesar `0.232043`, menandakan bahwa kata ini sangat relevan dan khas dalam menjelaskan lokasi atau identitas destinasi tersebut, yang memang terletak di kawasan Ancol.

Hasil ini membantu dalam mengidentifikasi kata-kata unik yang mencirikan setiap destinasi wisata secara deskriptif. Dengan kata lain, pendekatan ini memungkinkan sistem rekomendasi untuk memahami konten secara lebih dalam berdasarkan deskripsi alami destinasi, bukan hanya berdasarkan kategori

### 4.6. Persiapan Data (Collaborative Filtering)

Langkah pertama pada tahap ini adalah memperoleh daftar unik `pengguna (user)` dan `tempat (place)` yang terdapat dalam data rating. Hal ini dilakukan untuk merepresentasikan masing-masing entitas tersebut sebagai indeks numerik, yang diperlukan dalam proses pelatihan model Collaborative Filtering.
"""

# Mendapatkan daftar unik User_Id dan Place_Id
user_ids = df_ratings['User_Id'].unique().tolist()
place_ids = df_ratings['Place_Id'].unique().tolist()

print('list User_Id: ', user_ids)
print('list Place_Id: ', place_ids)

"""#### 4.6.1. Encoding User_Id dan Place_Id

Karena algoritma pembelajaran mesin tidak dapat langsung bekerja dengan data kategori dalam bentuk string atau integer tidak berurut, maka dilakukan proses encoding. Encoding ini bertujuan untuk mengubah `User_Id` dan `Place_Id` menjadi indeks integer yang berurutan dimulai dari 0. Proses ini menggunakan dictionary untuk memetakan nilai asli ke nilai yang sudah diencode, serta dictionary sebaliknya untuk keperluan decoding hasil prediksi nantinya.
"""

# Melakukan encoding User_Id
user_to_user_encoded = {user_id: idx for idx, user_id in enumerate(user_ids)}
# Membuat mapping dictionary untuk User_Id
user_encoded_to_user = {idx: user_id for idx, user_id in enumerate(user_ids)}

# Melakukan encoding Place_Id
place_to_place_encoded = {place_id: idx for idx, place_id in enumerate(place_ids)}
# Membuat mapping dictionary untuk Place_Id
place_encoded_to_place = {idx: place_id for idx, place_id in enumerate(place_ids)}

print('encoded angka ke User_Id: ', user_encoded_to_user)
print('encoded angka ke Place_Id: ', place_encoded_to_place)

"""Dengan encoding ini, setiap `User_Id` dan `Place_Id` telah dikonversi ke format numerik. Sebagai contoh, `User_Id` bernilai 1 mungkin di-encode menjadi 0, `User_Id` bernilai 2 menjadi 1, dan seterusnya. Proses ini menjadikan data lebih siap untuk dimasukkan ke dalam model pembelajaran mesin, khususnya model berbasis embedding yang umum digunakan dalam sistem rekomendasi.

#### 4.6.2. Menyiapkan Data Setelah Encoding

Selanjutnya, data rating asli akan ditransformasikan menjadi bentuk baru yang menggunakan nilai hasil encoding. Langkah ini akan menghasilkan dataset baru dengan kolom `user`, `place`, dan `rating`, di mana user dan place sudah dalam bentuk integer hasil encoding.
"""

# Membuat salinan dataset
df_collaborative = df_ratings.copy()

df_collaborative.head(2)

# Menambahkan kolom encoded
df_collaborative['user'] = df_collaborative['User_Id'].map(user_to_user_encoded)
df_collaborative['place'] = df_collaborative['Place_Id'].map(place_to_place_encoded)

# Menyimpan jumlah user dan jumlah tempat
num_users = len(user_to_user_encoded)
num_places = len(place_encoded_to_place)

print("Jumlah User:", num_users)
print("Jumlah Destinasi wisata:", num_places)

"""Dengan hasil ini, dataframe `df_collaborative` siap digunakan sebagai `input` untuk membangun model Collaborative Filtering. Kolom `user` dan `place` akan digunakan sebagai `input` ke model, sedangkan `Rating` akan menjadi target yang diprediksi.

#### 4.6.3. Normalisasi Rating

Pada tahap ini, dilakukan normalisasi terhadap kolom `Place_Ratings` agar nilai rating berada dalam `rentang [0, 1]`. Tujuannya adalah untuk memastikan bahwa semua nilai rating memiliki skala yang seragam, sehingga model dapat memproses data secara lebih optimal tanpa bias terhadap nilai numerik yang lebih besar.
"""

# Menentukan nilai minimum dan maksimum rating
min_rating = df_collaborative['Place_Ratings'].min()
max_rating = df_collaborative['Place_Ratings'].max()

# Melakukan normalisasi rating ke rentang [0, 1]
df_collaborative['normalized_rating'] = df_collaborative['Place_Ratings'].apply(
    lambda x: (x - min_rating) / (max_rating - min_rating)
)

"""Hasil normalisasi rating ditampilkan sebagai berikut"""

df_collaborative.head(2)

"""---

## **5. Modelling and Result**

Pada tahap ini, dua pendekatan sistem rekomendasi yang berbeda dikembangkan, yaitu Content-Based Filtering dan Collaborative Filtering. Masing-masing pendekatan memiliki metode tersendiri dalam menganalisis data dan memberikan rekomendasi destinasi wisata yang sesuai dengan preferensi pengguna.

### **5.1. Model Development with Content-Based Filtering**

Dalam pendekatan Content-Based Filtering, model dikembangkan berdasarkan informasi yang melekat pada setiap destinasi, seperti deskripsi dan kategori. Proses pembangunan model dilakukan melalui beberapa tahapan modelling dan result sebagai berikut:
- Menerapkan Proses Cosine Similarity.
- Mendapatkan Rekomendasi.

#### 5.1.1. Menerapkan Proses Cosine Similiarity

##### **a.  Kolom `Tags`**

Pada kasus ini, tahap Cosine Similarity digunakan untuk menghitung derajat kesamaan antar destinasi wisata berdasarkan informasi pada kolom `Tags`. Fungsi `cosine_similarity()` dari pustaka `sklearn.metrics.pairwise` digunakan untuk mengukur tingkat kemiripan antar vektor TF-IDF yang telah dibentuk sebelumnya. Perhitungan dilakukan terhadap objek `vectors_tags`, yaitu representasi vektor dari kombinasi deskripsi dan kategori destinasi. Hasil dari proses ini berupa matriks kesamaan `(similarity matrix)` yang menunjukkan nilai kemiripan antar setiap pasangan destinasi wisata.
"""

# Menghitung Cosine Similarity antara vektor-vektor 'Tags'
similarity_tags = cosine_similarity(vectors_tags, dense_output=True)

similarity_tags

"""Berikut merupakan representasi dari matriks kesamaan antar destinasi wisata yang diperoleh berdasarkan kolom `Tags`, dengan menampilkan nama destinasi sebagai indeks dan kolom. Untuk mempermudah visualisasi, ditampilkan 5 sampel kolom dan 10 sampel baris secara acak menggunakan fungsi `sample()`. Nilai pada matriks ini menunjukkan derajat kemiripan antar destinasi, di mana nilai mendekati 1 menandakan tingkat kesamaan yang tinggi."""

pd.DataFrame(
    similarity_tags,
    index = df_recommendation.Place_Name,
    columns = df_recommendation.Place_Name,
).sample(24, axis=1).sample(10, axis=0)

"""##### **b. Kolom `Description_Preprocessed`**

Perhitungan dilakukan terhadap objek `vectors_desc`, yaitu representasi vektor dari deskripsi destinasi. Hasil dari proses ini berupa matriks kesamaan `(similarity matrix)` yang menunjukkan nilai kemiripan antar setiap pasangan destinasi wisata.
"""

# Menghitung Cosine Similarity antara vektor-vektor 'Description' untuk menghitung kemiripan antar destinasi berdasarkan deskripsi
similarity_desc = cosine_similarity(vectors_desc, dense_output=True)

similarity_desc

"""Berikut merupakan representasi dari matriks kesamaan antar destinasi wisata berdasarkan kolom `Description_Preprocessed`, yaitu kolom yang hanya memuat informasi dari deskripsi asli destinasi tanpa mencampurkan kategori. Matriks ini dihitung menggunakan Cosine Similarity pada hasil representasi TF-IDF dari kolom tersebut. Untuk mempermudah tampilan, ditampilkan 5 sampel kolom dan 10 sampel baris secara acak. Nilai pada matriks ini menunjukkan seberapa mirip dua destinasi berdasarkan konten deskripsinya, dengan nilai mendekati 1 menunjukkan kemiripan yang tinggi."""

pd.DataFrame(
    similarity_desc,
    index = df_recommendation.Place_Name,
    columns = df_recommendation.Place_Name,
).sample(24, axis=1).sample(10, axis=0)

"""#### 5.1.2. Mendapatkan Rekomendasi

Selanjutnya, dibuat sebuah fungsi bernama `get_content_based_recommendations` dengan beberapa parameter berikut:
- `place_name`: Nama destinasi wisata yang dijadikan acuan untuk pencarian rekomendasi.
- `data`: Dataset yang berisi informasi lengkap mengenai destinasi wisata.
- `similarity_matrix`: Matriks kemiripan antar destinasi wisata yang telah dihitung sebelumnya, biasanya menggunakan metode seperti TF-IDF dan cosine similarity.
- `top_n`: Jumlah destinasi wisata yang ingin direkomendasikan, dengan nilai default sebanyak 10.

Dalam penerapannya, fungsi `get_content_based_recommendations` digunakan untuk menampilkan daftar rekomendasi destinasi wisata berdasarkan kemiripan fitur konten dari destinasi yang dipilih oleh pengguna.

`Rekomendasi dihasilkan dengan cara mengurutkan skor kemiripan dari yang tertinggi` dan mengabaikan destinasi itu sendiri. Hasil akhirnya berupa daftar `Place_Id` dari destinasi-destinasi wisata yang paling mirip dan layak untuk dikunjungi selanjutnya.
"""

def get_content_based_recommendations(place_name, data, similarity_matrix, top_n=10):
    """
    Menghasilkan rekomendasi destinasi wisata menggunakan Content-Based Filtering.

    Rekomendasi didasarkan pada kemiripan antara destinasi wisata yang dipilih dengan destinasi lainnya,
    menggunakan matriks similarity yang telah dihitung sebelumnya.

    Parameters:
    - place_name (str): Nama destinasi wisata yang dijadikan acuan rekomendasi.
    - data (DataFrame): Dataset yang berisi informasi destinasi wisata.
    - similarity_matrix (ndarray): Matriks similarity antar destinasi wisata.
    - top_n (int): Jumlah destinasi rekomendasi yang ingin ditampilkan (default = 10).

    Returns:
    - list: Daftar Place_Id destinasi wisata yang direkomendasikan.
    """
    # Memastikan destinasi yang diminta ada dalam dataset
    if place_name not in data['Place_Name'].values:
        print(f"'{place_name}' tidak ditemukan dalam dataset.")
        return []

    # Mendapatkan indeks destinasi dalam dataset
    place_idx = data[data['Place_Name'] == place_name].index[0]

    # Mendapatkan skor similarity untuk destinasi tersebut
    place_similarity = similarity_matrix[place_idx].flatten()

    # Mengurutkan skor similarity secara menurun
    similar_indices = place_similarity.argsort()[::-1]

    # Menghapus indeks destinasi itu sendiri dari daftar rekomendasi
    similar_indices = similar_indices[similar_indices != place_idx]

    # Mengambil top-n destinasi teratas
    top_indices = similar_indices[:top_n]

    # Mengambil Place_Id destinasi yang direkomendasikan
    recommended_place_ids = data.iloc[top_indices]['Place_Id'].tolist()

    return recommended_place_ids

def show_recommendations(place_name, similarity_matrix, df_recommendation, df_tourism_cleaned, source_label=""):
    """
    Menampilkan daftar destinasi wisata yang direkomendasikan berdasarkan similarity matrix tertentu.

    Parameters:
    - place_name (str): Nama tempat yang ingin direkomendasikan.
    - similarity_matrix (ndarray): Matriks similarity antar destinasi.
    - df_recommendation (DataFrame): DataFrame yang digunakan untuk menghitung rekomendasi.
    """
    recommended_place_ids = get_content_based_recommendations(
        place_name=place_name,
        data=df_recommendation,
        similarity_matrix=similarity_matrix,
        top_n=10
    )

    # Menyaring dan menampilkan destinasi yang direkomendasikan
    recommended_destinations = df_tourism_cleaned[
        df_tourism_cleaned['Place_Id'].isin(recommended_place_ids)
    ][['Place_Name', 'Category', 'Rating', 'Description']].copy()

    recommended_destinations.reset_index(drop=True, inplace=True)
    recommended_destinations.index += 1
    recommended_destinations.index.name = 'No.'

    # Menampilkan hasil rekomendasi
    print(f"\nRekomendasi destinasi wisata untuk '{place_name}' berdasarkan {source_label}:\n")
    display(recommended_destinations)

df_recommendation[df_recommendation.Place_Name.eq('Wisata Alam Kalibiru')]

place_to_recommend = 'Wisata Alam Kalibiru'

# Rekomendasi berdasarkan Tags
print('---' * 35)
show_recommendations(place_to_recommend, similarity_tags, df_recommendation, df_tourism_cleaned, source_label="Tags")

# Rekomendasi berdasarkan Description
print('---' * 35)
show_recommendations(place_to_recommend, similarity_desc, df_recommendation, df_tourism_cleaned, source_label="Description")

"""### 5.2. Model Development with Collaborative Filtering

#### 5.2.1. Membagi Data Untuk Training dan Validation
"""

# Menentukan ukuran training set (80% data)
train_size_cf = int(0.8 * len(df_collaborative))

# Membagi fitur (user, place) dan target (normalized_rating)
x_train_cf = df_collaborative[['user', 'place']].values[:train_size_cf]
y_train_cf = df_collaborative['normalized_rating'].values[:train_size_cf]

x_val_cf = df_collaborative[['user', 'place']].values[train_size_cf:]
y_val_cf = df_collaborative['normalized_rating'].values[train_size_cf:]

"""#### 5.2.2. Membangun Model Collaborative Filtering"""

# Membangun model Collaborative Filtering menggunakan Keras
class TourismRecNet(tf.keras.Model):
    def __init__(self, num_users, num_places, embedding_size, **kwargs):
        """
        Inisialisasi model Collaborative Filtering untuk sistem rekomendasi destinasi wisata.

        Parameters:
        - num_users (int): Jumlah pengguna (user) yang ada dalam dataset.
        - num_places (int): Jumlah tempat wisata (place) yang ada dalam dataset.
        - embedding_size (int): Ukuran embedding (dimensi vektor) yang digunakan untuk representasi pengguna dan tempat.
        """
        # Memanggil konstruktor dari kelas Model pada TensorFlow
        super(TourismRecNet, self).__init__(**kwargs)

        # Embedding untuk pengguna: Mengubah ID pengguna menjadi vektor embedding
        self.user_embedding = layers.Embedding(num_users, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=keras.regularizers.l2(1e-6))

        # Bias untuk pengguna: Menggunakan embedding untuk mempelajari bias individu pengguna
        self.user_bias = layers.Embedding(num_users, 1)

        # Embedding untuk tempat wisata: Mengubah ID tempat wisata menjadi vektor embedding
        self.place_embedding = layers.Embedding(num_places, embedding_size, embeddings_initializer='he_normal', embeddings_regularizer=keras.regularizers.l2(1e-6))

        # Bias untuk tempat wisata: Menggunakan embedding untuk mempelajari bias individu tempat wisata
        self.place_bias = layers.Embedding(num_places, 1)

    def call(self, inputs):
        """
        Melakukan forward pass untuk menghasilkan prediksi rating destinasi wisata.

        Parameters:
        - inputs (tf.Tensor): Tensor input berisi pasangan (user_id, place_id) dalam bentuk (batch_size, 2).

        Returns:
        - tf.nn.sigmoid: Prediksi rating untuk pasangan user dan place yang diberikan, yang dihitung
          dengan hasil dot product antara embedding pengguna dan tempat, serta menambahkan bias masing-masing.
        """
        # Mendapatkan vektor embedding untuk pengguna berdasarkan input user_id
        user_vector = self.user_embedding(inputs[:, 0])

        # Mendapatkan bias untuk pengguna
        user_bias = self.user_bias(inputs[:, 0])

        # Mendapatkan vektor embedding untuk tempat wisata berdasarkan input place_id
        place_vector = self.place_embedding(inputs[:, 1])

        # Mendapatkan bias untuk tempat wisata
        place_bias = self.place_bias(inputs[:, 1])

        # Menghitung dot product antara embedding pengguna dan tempat
        dot_product = tf.tensordot(user_vector, place_vector, 2)

        # Menambahkan bias pengguna dan bias tempat wisata pada hasil dot product
        x = dot_product + user_bias + place_bias

        # Mengembalikan hasil prediksi rating yang diproses dengan fungsi sigmoid untuk memastikan hasil antara 0 dan 1
        return tf.nn.sigmoid(x)

"""#### 5.2.3. Proses Training"""

# Inisialisasi dan compile model Collaborative Filtering
# Menggunakan 'num_users' (jumlah pengguna), 'num_places' (jumlah tempat wisata), dan ukuran embedding (misal 50)
model = TourismRecNet(num_users, num_places, 50)

model.compile(
    loss=tf.keras.losses.MeanSquaredError(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[
        tf.keras.metrics.RootMeanSquaredError(),
        tf.keras.metrics.MeanAbsoluteError()  # Tambahkan MAE di sini
    ]
)


# Melatih model dengan data training dan validation
history = model.fit(
    x=x_train_cf,  # Data training input (user_id, place_id)
    y=y_train_cf,  # Data training output (normalized rating)
    batch_size=32,  # Ukuran batch untuk pelatihan
    epochs=100,  # Jumlah epoch pelatihan
    validation_data=(x_val_cf, y_val_cf)  # Data validasi untuk evaluasi selama pelatihan
)

"""#### 5.2.4. Mendapatkan Rekomendasi

Selanjutnya, dibuat fungsi `recommend_by_collaborative_filtering` dengan beberapa parameter berikut:
- `user_id`: ID pengguna yang akan direkomendasikan tempat wisata.
- `model`: Model Collaborative Filtering yang telah dilatih dan digunakan untuk memprediksi rating.
- `data`: Dataset yang berisi interaksi pengguna terhadap tempat wisata (dalam bentuk rating).
- `place_encoded_to_place`: Mapping dari ID tempat yang sudah di-encode ke ID asli `(Place_Id)`.
- `top_n`: Jumlah rekomendasi yang diinginkan, dengan nilai default sebanyak 10 tempat.

Dalam penerapannya, fungsi ini digunakan untuk menampilkan daftar rekomendasi tempat wisata terbaik yang belum pernah dikunjungi oleh pengguna, berdasarkan prediksi rating tertinggi dari model. Output dari fungsi ini berupa tabel yang berisi informasi nama tempat, kategori, rating, dan deskripsi dari tempat wisata yang direkomendasikan.
"""

def recommend_by_collaborative_filtering(user_id, model, data, place_encoded_to_place, top_n=10):
    """
    Mengembalikan rekomendasi Collaborative Filtering untuk seorang pengguna berdasarkan model yang telah dilatih.

    Parameters:
    - user_id (int): ID pengguna yang akan direkomendasikan tempat.
    - model (tf.keras.Model): Model Collaborative Filtering yang telah dilatih dan digunakan untuk prediksi rating.
    - data (pd.DataFrame): Dataset yang berisi interaksi pengguna dengan tempat wisata (ratings).
    - place_encoded_to_place (dict): Mapping dari encoded Place ke Place_Id (untuk mengonversi kembali Place yang sudah di-encode).
    - top_n (int, optional): Jumlah rekomendasi yang diinginkan. Default adalah 10.

    Returns:
    - pd.DataFrame: Daftar rekomendasi tempat wisata, berisi nama tempat, kategori, rating, dan deskripsi.
    """

    # Mencari encoded user_id berdasarkan user_to_user_encoded
    user_encoded = user_to_user_encoded.get(user_id)

    # Jika user_id tidak ditemukan, mengembalikan DataFrame kosong
    if user_encoded is None:
        print("User ID tidak ditemukan. Tidak dapat memberikan rekomendasi.")
        return pd.DataFrame()

    # Mendapatkan tempat-tempat yang sudah pernah dikunjungi oleh pengguna
    user_places = data[data['User_Id'] == user_id]['Place_Id'].tolist()

    # Meng-encode ID tempat-tempat yang sudah dikunjungi
    user_places_encoded = [place_to_place_encoded.get(x) for x in user_places]

    # Mengidentifikasi tempat yang belum pernah dikunjungi oleh pengguna
    all_places = set(place_ids)
    places_not_visited = list(all_places - set(user_places))

    # Meng-encode ID tempat yang belum dikunjungi
    places_not_visited_encoded = [place_to_place_encoded.get(x) for x in places_not_visited]

    # Membuat array untuk input model: user_encoded berulang sebanyak jumlah tempat yang belum dikunjungi
    user_array = np.array([user_encoded] * len(places_not_visited_encoded))
    place_array = np.array(places_not_visited_encoded)

    # Menggunakan model untuk memprediksi rating yang diberikan oleh pengguna terhadap tempat yang belum dikunjungi
    predictions = model.predict(np.vstack([user_array, place_array]).T).flatten()

    # Mengurutkan prediksi rating dari yang tertinggi dan memilih top_n rekomendasi
    top_indices = predictions.argsort()[-top_n:][::-1]

    # Mendapatkan Place_Id dari tempat yang direkomendasikan
    recommended_place_ids = [place_encoded_to_place.get(places_not_visited_encoded[i]) for i in top_indices]

    # Mengambil informasi detail destinasi yang direkomendasikan berdasarkan Place_Id
    recommended_destinations = df_tourism_cleaned[
        df_tourism_cleaned['Place_Id'].isin(recommended_place_ids)
    ][['Place_Name', 'Category', 'Rating', 'Description']].copy()

    # Menambahkan kolom nomor urut untuk kemudahan referensi
    recommended_destinations.reset_index(drop=True, inplace=True)
    recommended_destinations.index += 1  # Menambahkan indeks mulai dari 1
    recommended_destinations.index.name = 'No.'  # Menambahkan label 'No.' di indeks

    return recommended_destinations

# Memilih satu sample User_Id secara acak dari df_collaborative
user_sample = df_collaborative['User_Id'].sample(1).iloc[0]

# Menampilkan tempat wisata dengan rating tertinggi dari user
user_places_rated = df_collaborative[df_collaborative['User_Id'] == user_sample]

if not user_places_rated.empty:
    print("\n" + '===' * 35)
    print(f'                          Tempat Wisata dengan Rating Tertinggi dari User ID {user_sample}')
    print('===' * 35)

    top_places_user = (user_places_rated.sort_values(by='Place_Ratings', ascending=False).head(5)['Place_Id'].values)

    top_places_info = df_tourism_cleaned[df_tourism_cleaned['Place_Id'].isin(top_places_user)][
        ['Place_Name', 'Category', 'Rating', 'Description']
    ]

    for row in top_places_info.itertuples(index=False):
        print(f"{row.Place_Name} ({row.Category}) - Rating: {row.Rating}")
        print(f"Deskripsi: {row.Description[:90]}...\n")  # Batasi deskripsi agar tidak terlalu panjang

else:
    print("User belum memiliki interaksi tempat yang bisa ditampilkan.")

# Mendapatkan rekomendasi tempat wisata untuk pengguna yang dipilih dengan Collaborative Filtering
collab_recommendations = recommend_by_collaborative_filtering(
    user_sample,              # User ID yang dipilih secara acak
    model,                    # Model Collaborative Filtering yang telah dilatih
    df_collaborative,         # Data yang berisi interaksi pengguna dengan tempat wisata
    place_encoded_to_place,   # Mapping dari encoded Place ke Place_Id
    top_n=10                  # Jumlah rekomendasi yang diinginkan (10 rekomendasi)
)

# Menampilkan Hasil Rekomendasi untuk User
print(f"\n Rekomendasi berdasarkan Collaborative Filtering untuk User ID: {user_sample} \n")

print('---' * 35)
print(f'                          Top 10 Rekomendasi Destinasi Wisata dengan Rating Tinggi')
print('---' * 35)

display(collab_recommendations)

"""---

## **6. Evaluation**

### 6.1. Evaluation of Content-Based Filtering Model

Evaluasi pada model Content-Based Filtering dilakukan dengan menggunakan metrik Precision@10, yang mengukur proporsi dari 10 rekomendasi teratas yang benar-benar relevan. Rekomendasi dianggap relevan jika memiliki kategori yang sama dengan destinasi asal atau memiliki kesamaan deskripsi (description similarity) di atas nilai threshold yang telah ditentukan, yaitu 0.5.
"""

def evaluate_precision(recommendation_data, similarity_tags, similarity_desc, places_to_evaluate, top_n=10, desc_threshold=0.5):
    """
    Mengevaluasi Precision@10 berdasarkan Category dan Description.

    Parameters:
    - recommendation_data (pd.DataFrame): Dataset destinasi wisata yang telah diproses.
    - similarity_tags (sparse matrix): Matriks similarity berdasarkan Tags (Description + Category).
    - similarity_desc (sparse matrix): Matriks similarity berdasarkan Description.
    - places_to_evaluate (list): Daftar nama tempat yang akan dievaluasi.
    - top_n (int, optional): Jumlah rekomendasi yang diinginkan. Default is 10.
    - desc_threshold (float, optional): Threshold untuk similarity Description. Default is 0.5.

    Returns:
    - pd.DataFrame: Hasil evaluasi Precision@10 untuk setiap tempat.
    """
    evaluation_results = []
    precision_list = []

    for place in places_to_evaluate:
        print(f"\nEvaluasi untuk '{place}':")

        # Mendapatkan Place_Id yang direkomendasikan
        recommended_place_ids = get_content_based_recommendations(place, recommendation_data, similarity_tags, top_n=top_n)

        if not recommended_place_ids:
            print(f"Rekomendasi untuk '{place}' kosong.")
            continue

        # Mengambil informasi detail destinasi berdasarkan Place_Id
        recommended_destinations = recommendation_data[
            recommendation_data['Place_Id'].isin(recommended_place_ids)
        ][['Place_Name', 'Category', 'Rating', 'Description_Preprocessed']].copy()

        # Menambahkan kolom nomor urut
        recommended_destinations.reset_index(drop=True, inplace=True)
        recommended_destinations.index += 1
        recommended_destinations.index.name = 'No.'

        # Mendapatkan Category dan Description_Preprocessed dari tempat input
        input_place = recommendation_data[recommendation_data['Place_Name'] == place].iloc[0]
        input_category = input_place['Category']
        input_desc_preprocessed = input_place['Description_Preprocessed']

        # Menghitung similarity Description antara input place dan semua rekomendasi
        input_idx = recommendation_data[recommendation_data['Place_Name'] == place].index[0]
        desc_similarities = similarity_desc[input_idx, recommended_destinations.index - 1].flatten()

        # Menentukan relevansi berdasarkan Category atau Description similarity
        recommended_destinations['Description_Similarity'] = desc_similarities
        recommended_destinations['Relevance'] = ((recommended_destinations['Category'] == input_category) |
                                                  (recommended_destinations['Description_Similarity'] >= desc_threshold)).astype(int)

        # Menampilkan hasil rekomendasi beserta kesamaan deskripsi
        print(f"Rekomendasi:")
        display(recommended_destinations[['Place_Name', 'Category', 'Rating', 'Description_Similarity', 'Relevance']])

        # Menghitung True Positives (TP) dan False Positives (FP)
        TP = recommended_destinations['Relevance'].sum()
        FP = top_n - TP

        # Menghitung Precision@10
        precision = TP / top_n
        print(f"True Positive (TP): {TP}")
        print(f"False Positive (FP): {FP}")
        print(f"Precision@10 untuk '{place}': {precision * 100:.2f}%")
        print(f"Nilai kesamaan deskripsi untuk setiap rekomendasi:")

        # Menyimpan hasil evaluasi
        evaluation_results.append({
            'Place': place,
            'Precision@10': f"{precision * 100:.2f}%"
        })

        # Menyimpan nilai precision untuk rata-rata
        precision_list.append(precision)

    # Menghitung rata-rata Precision@10
    avg_precision = np.mean(precision_list) if precision_list else 0

    return pd.DataFrame(evaluation_results), avg_precision

# Mendefinisikan daftar tempat untuk evaluasi
places_to_evaluate = ['Museum Perangko']

# Mengevaluasi Precision@10 menggunakan fungsi evaluate_precision
evaluation_df, avg_precision = evaluate_precision(
    df_recommendation,
    similarity_tags,      # Matriks similarity berdasarkan Tags (Description + Category)
    similarity_desc,      # Matriks similarity berdasarkan Description
    places_to_evaluate,
    top_n=10,
    desc_threshold=0.5    # Threshold untuk similarity Description
)

# Menampilkan hasil evaluasi Precision@10
print("\n=== Hasil Evaluasi Precision@10 ===")
display(evaluation_df)

"""Semua rekomendasi yang diberikan memiliki kategori yang sama (Budaya) dengan tempat asal, sehingga dianggap relevan. Meskipun similarity pada deskripsi cenderung rendah, model tetap berhasil menghasilkan rekomendasi yang tepat berdasarkan kategori. Hal ini menunjukkan bahwa pemanfaatan tag-based similarity cukup efektif.

### 6.2. Evaluation of Collaborative Filtering Model
"""

# Membuat figure dan dua axes untuk plot berdampingan
fig, axs = plt.subplots(1, 2, figsize=(14, 5))  # 1 baris, 2 kolom

# Plot RMSE
axs[0].plot(history.history['root_mean_squared_error'], label='Train')
axs[0].plot(history.history['val_root_mean_squared_error'], label='Validation')
axs[0].set_title('Perkembangan RMSE Selama Training')
axs[0].set_ylabel('Root Mean Squared Error (RMSE)')
axs[0].set_xlabel('Epoch')
axs[0].legend(loc='upper right')
axs[0].set_ylim(0, 1)

# Plot MAE
axs[1].plot(history.history['mean_absolute_error'], label='Train')
axs[1].plot(history.history['val_mean_absolute_error'], label='Validation')
axs[1].set_title('Perkembangan MAE Selama Training')
axs[1].set_ylabel('Mean Absolute Error (MAE)')
axs[1].set_xlabel('Epoch')
axs[1].legend(loc='upper right')
axs[1].set_ylim(0, 1)

# Menampilkan semua plot
plt.tight_layout()
plt.show()

"""Perkembangan error selama proses pelatihan juga ditampilkan dalam bentuk grafik garis. Grafik ini menunjukkan penurunan nilai RMSE dan MAE seiring dengan bertambahnya epoch, baik pada data training maupun validation, yang mengindikasikan bahwa model mengalami proses pelatihan yang stabil."""

# Mendapatkan prediksi untuk data validasi
y_pred_cf = model.predict(x_val_cf).flatten()

# Menghitung RMSE dan MAE
rmse_cf = np.sqrt(mean_squared_error(y_val_cf, y_pred_cf))
mae_cf = mean_absolute_error(y_val_cf, y_pred_cf)

print(f"Collaborative Filtering - RMSE: {rmse_cf:.4f}")
print(f"Collaborative Filtering - MAE: {mae_cf:.4f}")

# Plot RMSE dan MAE untuk Collaborative Filtering
plt.figure(figsize=(8,6))
plt.bar(['RMSE', 'MAE'], [rmse_cf, mae_cf], color=['skyblue', 'orange'])
plt.title('Evaluasi Kinerja Model Collaborative Filtering')
plt.xlabel('Metrik Evaluasi')
plt.ylabel('Nilai Kesalahan')
plt.ylim(0, 1)
for i, v in enumerate([rmse_cf, mae_cf]):
    plt.text(i, v + 0.01, f"{v:.4f}", ha='center')
plt.show()

"""Nilai RMSE dan MAE yang diperoleh menunjukkan bahwa model Collaborative Filtering mampu memprediksi rating dengan tingkat kesalahan yang relatif kecil. Untuk memberikan gambaran yang lebih jelas, kedua metrik ini divisualisasikan dalam bentuk grafik batang. Nilai RMSE sebesar 0.3642 dan MAE sebesar 0.3145 mengindikasikan bahwa prediksi model mendekati nilai aktual yang diberikan oleh pengguna, dengan rata-rata kesalahan kurang dari 0.4 poin dari skala rating (0–5). Hal ini menandakan bahwa model mampu melakukan prediksi rating dengan cukup akurat.

---

## **7. Keterkaitan dengan Business Understanding**

Problem Statements:

  - Bagaimana cara memberikan rekomendasi destinasi wisata yang relevan berdasarkan deskripsi dan kategori konten?

    → Pendekatan Content-Based Filtering berhasil menjawab masalah ini dengan menggunakan informasi deskriptif dan kategori dari destinasi. Evaluasi dengan Precision@10 menghasilkan akurasi hingga 100%, menunjukkan bahwa sistem mampu memberikan rekomendasi yang sangat relevan terhadap preferensi pengguna.

  - Bagaimana cara menggunakan data rating pengguna untuk meningkatkan akurasi rekomendasi?

    → Pendekatan Collaborative Filtering membuktikan bahwa pola penilaian pengguna lain dapat dimanfaatkan untuk menghasilkan rekomendasi yang bersifat personal dan lebih akurat. Model ini mampu mencapai RMSE sebesar 0.3642 dan MAE sebesar 0.3145, menandakan bahwa sistem memiliki kesalahan prediksi yang rendah.

  - Bagaimana cara mengukur relevansi rekomendasi agar sistem dapat memberikan hasil yang tepat?

    → Evaluasi dilakukan menggunakan metrik yang sesuai dengan pendekatannya: Precision@10 untuk pendekatan berbasis konten, serta RMSE dan MAE untuk pendekatan kolaboratif. Penggunaan metrik ini memastikan bahwa rekomendasi tidak hanya personal tetapi juga tepat sasaran dan dapat dipertanggungjawabkan secara kuantitatif.

Goals:
  - Membangun sistem rekomendasi yang mampu memberikan rekomendasi tempat wisata secara personal berdasarkan konten dan perilaku pengguna.
  - Meningkatkan kepuasan pengguna melalui sistem yang mampu menyesuaikan saran destinasi dengan preferensi individual tanpa bergantung pada pencarian manual.
  - Mendorong eksposur destinasi yang kurang populer namun potensial melalui personalisasi dan pemanfaatan data historis.

Solution Statements:
  - Pendekatan Content-Based Filtering dilakukan dengan mengolah deskripsi dan kategori destinasi menggunakan teknik TF-IDF Vectorizer, kemudian menghitung cosine similarity antar destinasi untuk menghasilkan rekomendasi yang mirip dengan tempat favorit pengguna.
  - Evaluasi menggunakan Precision@10 menunjukkan bahwa sistem dapat memberikan 10 rekomendasi yang seluruhnya relevan terhadap masukan awal pengguna.
  - Pendekatan Collaborative Filtering dibangun menggunakan teknik embedding pada data rating pengguna dan destinasi, disertai normalisasi data untuk meningkatkan stabilitas model. Prediksi dilakukan dengan model neural network sederhana.
  - Evaluasi model menggunakan Root Mean Square Error (RMSE) dan Mean Absolute Error (MAE) menunjukkan performa yang sangat baik dan minim kesalahan prediksi.

Dengan demikian, dua pendekatan yang digunakan, yaitu Content-Based Filtering dan Collaborative Filtering, berhasil menjawab semua problem statement dan memenuhi tujuan proyek, serta memberikan dampak nyata terhadap pengembangan pariwisata berbasis data.

Setiap solusi yang diimplementasikan memiliki kontribusi yang signifikan:
- Pendekatan Content-Based Filtering berbasis TF-IDF dan cosine similarity memungkinkan sistem memberikan rekomendasi relevan bahkan ketika pengguna belum banyak berinteraksi dengan sistem. Hal ini berdampak langsung pada penyelesaian masalah cold start pada pengguna baru dan memperkuat personalisasi, sesuai dengan temuan `Syakura (2024)`.
- Evaluasi menggunakan metrik `Precision@10` memastikan bahwa rekomendasi yang diberikan sistem benar-benar relevan, sehingga mengurangi beban pengguna dalam menyaring informasi yang terlalu banyak dan mendukung pengalaman wisata yang lebih efisien.
- Pendekatan Collaborative Filtering melalui embedding dan normalisasi berhasil memetakan pola perilaku pengguna lain, sehingga mampu merekomendasikan destinasi yang belum populer namun sesuai dengan minat pengguna. Ini mendukung pemerataan promosi destinasi wisata yang selama ini kurang terekspos, sebagaimana dikemukakan oleh `Cholil et al. (2023)`.
- Evaluasi CF menggunakan metrik RMSE dan MAE menunjukkan bahwa model memiliki kemampuan prediktif yang baik dalam memperkirakan preferensi pengguna, yang secara tidak langsung mendukung keandalan sistem dalam jangka panjang.

Secara keseluruhan, sistem yang dibangun tidak hanya akurat secara teknis, tetapi juga memiliki nilai bisnis yang tinggi, baik dalam meningkatkan kualitas personalisasi layanan wisata maupun dalam mempromosikan destinasi secara lebih merata dan efektif. Dengan menggabungkan aspek teknis dan dampak praktis, proyek ini memberikan kontribusi nyata terhadap transformasi digital di sektor pariwisata.
"""